{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Poet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from urllib.request import urlopen  # Py3\n",
    "\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TextLibrary class: text library for training, encoding, batch generation,\n",
    "# and formatted source display\n",
    "class TextLibrary:\n",
    "    def __init__(self, descriptors, max=100000000):\n",
    "        self.descriptors=descriptors\n",
    "        self.data=''\n",
    "        self.files=[]\n",
    "        self.c2i = {}\n",
    "        self.i2c = {}\n",
    "        index = 1\n",
    "        for descriptor in descriptors:\n",
    "            fd={}\n",
    "            if descriptor[:4] == 'http':\n",
    "                try:\n",
    "                    dat = urlopen(descriptor).read().decode('utf-8')\n",
    "                    self.data += dat\n",
    "                    fd[\"name\"] = descriptor\n",
    "                    fd[\"data\"] = dat\n",
    "                    fd[\"index\"] = index\n",
    "                    index += 1\n",
    "                    self.files.append(fd)\n",
    "                except Exception as e:\n",
    "                    print(f\"Can't download {descriptor}: {e}\")\n",
    "            else:\n",
    "                fd[\"name\"] = os.path.splitext(os.path.basename(descriptor))[0]\n",
    "                try:\n",
    "                    f = open(descriptor)\n",
    "                    dat = f.read(max)\n",
    "                    self.data += dat\n",
    "                    fd[\"data\"] = dat\n",
    "                    fd[\"index\"] = index\n",
    "                    index += 1\n",
    "                    self.files.append(fd)\n",
    "                    f.close()\n",
    "                except Exception as e:\n",
    "                    print(f\"ERROR: Cannot read: {filename}: {e}\")\n",
    "        ind = 0\n",
    "        for c in self.data:  # sets are not deterministic\n",
    "            if c not in self.c2i:\n",
    "                self.c2i[c] = ind\n",
    "                self.i2c[ind] = c\n",
    "                ind += 1\n",
    "        self.ptr = 0\n",
    "            \n",
    "    def print_colored_IPython(self, textlist, pre='', post=''):\n",
    "        bgcolors = ['#d4e6f1', '#d8daef', '#ebdef0', '#eadbd8', '#e2d7d5', '#edebd0',\n",
    "                    '#ecf3cf', '#d4efdf', '#d0ece7', '#d6eaf8', '#d4e6f1', '#d6dbdf',\n",
    "                    '#f6ddcc', '#fae5d3', '#fdebd0', '#e5e8e8', '#eaeded', '#A9CCE3']\n",
    "        out = ''\n",
    "        for txt, ind in textlist:\n",
    "            txt = txt.replace('\\n','<br>')\n",
    "            if ind==0:\n",
    "                out += txt\n",
    "            else:\n",
    "                out += \"<span style=\\\"background-color:\"+bgcolors[ind%16]+\";\\\">\" + txt +\\\n",
    "                       \"</span>\"+\"<sup>[\" + str(ind) + \"]</sup>\"\n",
    "        display(HTML(pre+out+post))\n",
    "        \n",
    "    def source_highlight(self, txt, minQuoteSize=10):\n",
    "        tx = txt\n",
    "        out = []\n",
    "        qts = []\n",
    "        txsrc=[(\"Sources: \", 0)]\n",
    "        sc=False\n",
    "        noquote = ''\n",
    "        while len(tx)>0:  # search all library files for quote 'txt'\n",
    "            mxQ = 0\n",
    "            mxI = 0\n",
    "            mxN = ''\n",
    "            found = False\n",
    "            for f in self.files:  # find longest quote in all texts\n",
    "                p = minQuoteSize\n",
    "                if p<=len(tx) and tx[:p] in f[\"data\"]:\n",
    "                    p = minQuoteSize + 1\n",
    "                    while p<=len(tx) and tx[:p] in f[\"data\"]:\n",
    "                        p += 1\n",
    "                    if p-1>mxQ:\n",
    "                        mxQ = p-1\n",
    "                        mxI = f[\"index\"]\n",
    "                        mxN = f[\"name\"]\n",
    "                        found = True\n",
    "            if found:  # save longest quote for colorizing\n",
    "                if len(noquote)>0:\n",
    "                    out.append((noquote, 0))\n",
    "                    noquote = ''\n",
    "                out.append((tx[:mxQ],mxI))\n",
    "                tx = tx[mxQ:]\n",
    "                if mxI not in qts:  # create a new reference, if first occurence\n",
    "                    qts.append(mxI)\n",
    "                    if sc:\n",
    "                        txsrc.append((\", \", 0))\n",
    "                    sc = True\n",
    "                    txsrc.append((mxN,mxI))\n",
    "            else:\n",
    "                noquote += tx[0]\n",
    "                tx = tx[1:]\n",
    "        if len(noquote)>0:\n",
    "            out.append((noquote, 0))\n",
    "            noquote = ''\n",
    "        self.print_colored_IPython(out)\n",
    "        if len(qts)>0:  # print references, if there is at least one source\n",
    "            self.print_colored_IPython(txsrc, pre=\"<small><p style=\\\"text-align:right;\\\">\",\n",
    "                                     post=\"</p></small>\")\n",
    "    \n",
    "    def get_slice(self, length):\n",
    "        if (self.ptr + length >= len(self.data)):\n",
    "            self.ptr = 0\n",
    "        if self.ptr == 0:\n",
    "            rewind = True\n",
    "        else:\n",
    "            rewind = False\n",
    "        sl = self.data[self.ptr:self.ptr+length]\n",
    "        self.ptr += length\n",
    "        return sl, rewind\n",
    "    \n",
    "    def decode(self, ar):\n",
    "         return ''.join([self.i2c[ic] for ic in ar])\n",
    "            \n",
    "    def get_random_slice(self, length):\n",
    "        p = random.randrange(0,len(self.data)-length)\n",
    "        sl = self.data[p:p+length]\n",
    "        return sl\n",
    "    \n",
    "    def get_slice_array(self, length):\n",
    "        ar = np.array([c for c in self.get_slice(length)[0]],dtype=int)\n",
    "        return ar\n",
    "        \n",
    "    def get_sample(self, length):\n",
    "        s, rewind = self.get_slice(length+1)\n",
    "        X = np.array([self.c2i[c] for c in s[:-1]],dtype=int)\n",
    "        y = np.array([self.c2i[c] for c in s[1:]],dtype=int)\n",
    "        return (X, y, rewind)\n",
    "    \n",
    "    def get_random_sample(self, length):\n",
    "        s = self.get_random_slice(length+1)\n",
    "        X = np.array([self.c2i[c] for c in s[:-1]],dtype=int)\n",
    "        y = np.array([self.c2i[c] for c in s[1:]],dtype=int)\n",
    "        return (X, y)\n",
    "    \n",
    "    def get_sample_batch(self, batch_size, length):\n",
    "        smpX = np.zeros((batch_size,length),dtype=int)\n",
    "        smpy = np.zeros((batch_size,length),dtype=int)\n",
    "        for i in range(batch_size):\n",
    "            smpX[i,:], smpy[i,:], _ = self.get_sample(length)\n",
    "        return smpX, smpy\n",
    "        \n",
    "    def get_random_sample_batch(self, batch_size, length):\n",
    "        smpX = np.zeros((batch_size,length),dtype=int)\n",
    "        smpy = np.zeros((batch_size,length),dtype=int)\n",
    "        for i in range(batch_size):\n",
    "            smpX[i,:], smpy[i,:] = self.get_random_sample(length)\n",
    "        return smpX, smpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters and data sources\n",
    "\n",
    "The library description can contain a list of text-files, referencing either a local file path or an http(s) URL. It is possible, to add files in different languages. The net will learn by itself to generate text in only one of the languages. Color-markup is used in generated texts to identify memorized parts of the original texts.\n",
    "``` python\n",
    "libdesc = {\n",
    "    \"name\": \"My lib\",\n",
    "    \"description\": \"several texts\",\n",
    "    \"lib\": [\n",
    "        'data/some-english.txt',\n",
    "        'data/some-french.txt',\n",
    "        'data/some-german.txt',\n",
    "        'data/some-more.txt',\n",
    "        'http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/100/100-0.txt'\n",
    "    ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "libdesc = {\n",
    "    \"name\": \"TinyShakespeare\",\n",
    "    \"description\": \"Shakespeare's collected works from project Gutenberg\",\n",
    "    \"lib\": [\n",
    "        'http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/100/100-0.txt',\n",
    "    ]\n",
    "}\n",
    "\n",
    "textlib = TextLibrary(libdesc[\"lib\"])\n",
    "\n",
    "use_shakespeare = False\n",
    "\n",
    "if use_shakespeare or not os.path.exists('data/lib.json'):\n",
    "    # Default model parameters for shakespeare:\n",
    "    model_params_shakespeare = {\n",
    "        \"model_name\": \"lib\",\n",
    "        \"vocab_size\": len(textlib.i2c),\n",
    "        \"neurons\": 256,\n",
    "        \"layers\": 2,\n",
    "        \"learning_rate\": 1.e-3,\n",
    "        \"steps\": 80,\n",
    "        \"batch_size\": 128\n",
    "    }\n",
    "    model_params = model_params_shakespeare\n",
    "else:        \n",
    "    # Look for optional json description of a library:\n",
    "    with open('data/lib.json') as data_file:    \n",
    "        libdesc = json.load(data_file)\n",
    "        textlib = TextLibrary(libdesc[\"lib\"])\n",
    "        model_params_lib = {\n",
    "            \"model_name\": \"lib\",\n",
    "            \"vocab_size\": len(textlib.i2c),\n",
    "            \"neurons\": 512,\n",
    "            \"layers\": 4,\n",
    "            \"learning_rate\": 2.e-4,\n",
    "            \"steps\": 80,\n",
    "            \"batch_size\": 128\n",
    "        }\n",
    "        model_params = model_params_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(p, dim):\n",
    "    o=np.zeros(p.shape+(dim,), dtype=int)\n",
    "    for y in range(p.shape[0]):\n",
    "        for x in range(p.shape[1]):\n",
    "            o[y,x,p[y,x]]=1\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = model_params['batch_size']\n",
    "vocab_size = model_params['vocab_size']\n",
    "steps = model_params['steps']\n",
    "\n",
    "force_cpu=False\n",
    "\n",
    "if torch.cuda.is_available() and force_cpu is not True:\n",
    "    device='cuda'\n",
    "    use_cuda = True\n",
    "else:\n",
    "    device='cpu'\n",
    "    use_cuda = False\n",
    "\n",
    "def get_data():\n",
    "    X, y=textlib.get_random_sample_batch(batch_size, steps)\n",
    "    Xo = one_hot(X, vocab_size)\n",
    "    \n",
    "    # Xt = Tensor(torch.from_numpy(np.array(Xo,dtype=np.float32)), requires_grad=False, dtype=torch.float32, device=device)\n",
    "    # yt = Tensor(torch.from_numpy(y), requires_grad=False, dtype=torch.int32, device=device)\n",
    "    Xt = Tensor(torch.from_numpy(np.array(Xo,dtype=np.float32))).to(device)\n",
    "    Xt.requires_grad_(False)\n",
    "    yt = torch.LongTensor(torch.from_numpy(np.array(y,dtype=np.int64))).to(device)\n",
    "    yt.requires_grad_(False)\n",
    "    return Xt, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gpu_mem(context=\"all\"):\n",
    "    if use_cuda:\n",
    "        print(\"[{}] Memory allocated: {} max_alloc: {} cached: {} max_cached: {}\".format(context,torch.cuda.memory_allocated(), torch.cuda.max_memory_allocated(), torch.cuda.memory_cached(), torch.cuda.max_memory_cached()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The char-rnn model (deep LSTMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Poet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, device):\n",
    "        super(Poet, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.device=device\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=0)\n",
    "        \n",
    "        self.demb = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)  # negative dims are a recent thing (as 2018-03), remove for old vers.\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        self.h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n",
    "        self.c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n",
    "\n",
    "    def forward(self, inputx, steps):\n",
    "        self.lstm.flatten_parameters()\n",
    "        hn, (self.h0, self.c0) = self.lstm(inputx.to(self.device), (self.h0, self.c0))\n",
    "        hnr = hn.contiguous().view(-1,self.hidden_size)\n",
    "        op = self.demb(hnr)\n",
    "        opr = op.view(-1, steps ,self.output_size)\n",
    "        return opr\n",
    "\n",
    "    def generate(self, n, start=None):\n",
    "        s=''\n",
    "        torch.set_grad_enabled(False)\n",
    "        if start==None or len(start)==0:\n",
    "            start=' '\n",
    "        self.init_hidden(1)\n",
    "        for c in start:\n",
    "            X=np.array([[textlib.c2i[c]]])\n",
    "            Xo=one_hot(X,self.output_size)\n",
    "            Xt = Tensor(torch.from_numpy(np.array(Xo,dtype=np.float32))).to(self.device)\n",
    "            ypl = self.forward(Xt,1)\n",
    "            ypl2 = ypl.view(-1,self.output_size)\n",
    "            yp = self.softmax(ypl2)\n",
    "        for i in range(n):\n",
    "            ypc=Tensor.cpu(yp.detach()) # .cpu()\n",
    "            y_pred=ypc.numpy()\n",
    "            inds=list(range(self.output_size))\n",
    "            ind = np.random.choice(inds, p=y_pred.ravel())\n",
    "            s=s+textlib.i2c[ind]\n",
    "            X=np.array([[ind]])\n",
    "            Xo=one_hot(X,self.output_size)\n",
    "            Xt = Tensor(torch.from_numpy(np.array(Xo,dtype=np.float32))).to(self.device)\n",
    "            ypl = self.forward(Xt,1)\n",
    "            ypl2 = ypl.view(-1,self.output_size)\n",
    "            yp = self.softmax(ypl2)\n",
    "        torch.set_grad_enabled(True)\n",
    "        return s    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a poet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poet = Poet(vocab_size, model_params['neurons'], model_params['layers'], vocab_size, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = model_params['learning_rate']\n",
    "\n",
    "opti = torch.optim.Adam(poet.parameters(),lr=learning_rate);\n",
    "\n",
    "bok=0\n",
    "\n",
    "def train(Xt, yt, bPr=False):\n",
    "    poet.zero_grad()\n",
    "\n",
    "    poet.init_hidden(Xt.size(0))\n",
    "    output = poet(Xt, steps)\n",
    "    \n",
    "    olin=output.view(-1,vocab_size)\n",
    "    _, ytp=torch.max(olin,1)\n",
    "    ytlin=yt.view(-1)\n",
    "\n",
    "    pr=0.0\n",
    "    if bPr: # Calculate precision\n",
    "        ok=0\n",
    "        nok=0\n",
    "        for i in range(ytlin.size()[0]):\n",
    "            i1=ytlin[i].item()\n",
    "            i2=ytp[i].item()\n",
    "            if i1==i2:\n",
    "                ok = ok + 1\n",
    "            else:\n",
    "                nok = nok+1\n",
    "            pr=ok/(ok+nok)\n",
    "            \n",
    "    loss = criterion(olin, ytlin)\n",
    "    ls = loss.item()\n",
    "    loss.backward()\n",
    "    opti.step()\n",
    "\n",
    "    return ls, pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.2583242444992067 Precision: 0.26474609375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br>m iEBC.b\r",
       " TIa ertle shi s'theifameu to hod. .a ? np re\r",
       "<br>  h trhefme,e o tn velsiearmewe etdo.s g e  ilugeatu\r",
       "\r",
       "is  y y cedpieuulh veonh; hot st a todssulnehncarl? . I iwp s i volodsr.  g ire \r",
       " ay iegnd\r",
       "  y mgtgoncaat atweutlam hhiateo tfl,ve hefe\r",
       "t\r",
       " re  izdfaatgo  euwi nbutouorege\r",
       "<br>   eaysiur w,oohe uiriln\r",
       "\r",
       "<br> E we mtas ni eit !N <br>\r",
       "ai  e i .ry  uere bd. thrutetus aucee\r",
       "d alrf er ae de\r",
       "<br>\r",
       "  puorr ye . Yoie  ondimte:\r",
       "<br> iE.<br> u.\r",
       "<br> BC SE<br>h,\r",
       "ib  pnhefolejgeeibe dtdul n usa idauehc theMts  he<br>  dho’ptajv"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.42802467918396 Precision: 0.37158203125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " AMITAN.\r",
       "<br>Deichat tund othunlithen!\r",
       "<br>Tist larsiriso, sale yeud on lolg our sam. a gene au houy woln?\r",
       "<br>   HGteac<span style=\"background-color:#d8daef;\">s\r",
       "<br>        </span><sup>[1]</sup>fiti wit  s ware heeendes I geset; neus goms op inat, avild eom traang, I ge-Ispills ; well nod vaaes warsine thys's Gpassoth-\r",
       "<br>Whigteupbim.\r",
       "<br>Manaspy rheu, toe thet wofe stes cuncesd ton thout. dithit leraned hle at ot  Oit of woree nobksare any\r",
       "<br>  \r",
       "<br>  At thiy dpyem he co pisint is a'dg: lnekcine heriy atis ghed, nafisd sath o fonserk’d, soorqith core mon, opeore deovereor sa"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d8daef;\">http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/100/100-0.txt</span><sup>[1]</sup></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.1744169387817385 Precision: 0.39853515625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "  JOMIRANOR. Kest he shate tn<span style=\"background-color:#d8daef;\">ot out wha</span><sup>[1]</sup><span style=\"background-color:#d8daef;\">ve of thei</span><sup>[1]</sup>ll<span style=\"background-color:#d8daef;\">s he in whe</span><sup>[1]</sup>ek sb<span style=\"background-color:#d8daef;\">ars;\r",
       "<br>    </span><sup>[1]</sup>Geos on bid sleth ins than sas sith a ane notpay’d,,\r",
       "<br>He ant ofer lethie fite’d abpee, frey s<span style=\"background-color:#d8daef;\">ather.\r",
       "<br>    And </span><sup>[1]</sup>bow Gily breof a cueg yit thear asm wom tere.\r",
       "<br>\r",
       "<br>TECHOCAUSSiS. B TSIRTH. Exor auth\r",
       "<br>Hraghe memadt the sbae ncine tome'd Ind fores ins corosi<span style=\"background-color:#d8daef;\">go;\r",
       "<br>     </span><sup>[1]</sup>owithed, Ifshine thal  the tha ceiven folg.\r",
       "<br>  TERUTHca in. FIm. Whet thaneore blacr ino hivbicins\r",
       "<br>Whet frit fot w in' wtonld.\r",
       "<br>Brox, niviag meve d<span style=\"background-color:#d8daef;\">on:\r",
       "<br>    I </span><sup>[1]</sup>wacl "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d8daef;\">http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/100/100-0.txt</span><sup>[1]</sup></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.0566485204696656 Precision: 0.42158203125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#d8daef;\">                    </span><sup>[1]</sup>(S<span style=\"background-color:#d8daef;\">ours, with </span><sup>[1]</sup>you in modt thas <span style=\"background-color:#d8daef;\">ear not me</span><sup>[1]</sup>cts cust thie, r<span style=\"background-color:#d8daef;\">ow I got the</span><sup>[1]</sup>y more<span style=\"background-color:#d8daef;\"> note the </span><sup>[1]</sup>besher aglo gon.\r",
       "<br>  ENOT. Su kosh Ke lold of cominir, G macour a lorven ator,\r",
       "<br>Tould os has whors five. SH'O<span style=\"background-color:#d8daef;\">                                     P</span><sup>[1]</sup>hyoud apal I mute tho f<span style=\"background-color:#d8daef;\">ake the wal</span><sup>[1]</sup>e and fivlis; a stenlald.\r",
       "<br>\r",
       "<br>Bis a, mo a coust ofy\r",
       "<br>    I um weuld of a cor, for sen, dut<span style=\"background-color:#d8daef;\"> more, the</span><sup>[1]</sup>s ine eno<span style=\"background-color:#d8daef;\">ng to and </span><sup>[1]</sup>by noMagsnof-<span style=\"background-color:#d8daef;\">\r",
       "<br>    in a</span><sup>[1]</sup>ret a no shallong, Is tall the and Caveacion cos, landis, at me thet I hers"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d8daef;\">http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/100/100-0.txt</span><sup>[1]</sup></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.978953791618347 Precision: 0.438671875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#d8daef;\">         t</span><sup>[1]</sup>ut, suetle his ligrri<span style=\"background-color:#d8daef;\">s, if the </span><sup>[1]</sup>hiscencint;\r",
       "<br>   [Wand fath ynactord yoce ax somine sa<span style=\"background-color:#d8daef;\">ber;\r",
       "<br>    </span><sup>[1]</sup>Henath worf graor'st tervest, to    marting<span style=\"background-color:#d8daef;\"> he;\r",
       "<br>    No</span><sup>[1]</sup>ud madtes! So tionst your, heelmles wir, the exevave thour be<span style=\"background-color:#d8daef;\">ay\r",
       "<br>    En</span><sup>[1]</sup>dilim huse maull<span style=\"background-color:#d8daef;\">ad, and so wi</span><sup>[1]</sup>viin<span style=\"background-color:#d8daef;\">e\r",
       "<br>    wen</span><sup>[1]</sup><span style=\"background-color:#d8daef;\">store.\r",
       "<br>\r",
       "<br></span><sup>[1]</sup>CANTIA.\r",
       "<br>Whe stiss om tare senst Ky\r",
       "<br>  thele th<span style=\"background-color:#d8daef;\">it there, </span><sup>[1]</sup>hans so leve doo, shi<span style=\"background-color:#d8daef;\">s then of </span><sup>[1]</sup>I kave\r",
       "doust to mar<span style=\"background-color:#d8daef;\">e,\r",
       "<br>For ha</span><sup>[1]</sup>t I tlord dearma, saly\r",
       "<br>It un shvele My ampl not gom rintse ivaut;\r",
       "<br>\r",
       "<br>\r",
       "<br>JUCIWPIPEO. To<span style=\"background-color:#d8daef;\">n say,\r",
       "<br>    </span><sup>[1]</sup>An"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d8daef;\">http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/100/100-0.txt</span><sup>[1]</sup></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.919269054412842 Precision: 0.4662109375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "   Gend of watisine foramading tut to ille to J<span style=\"background-color:#d8daef;\">yes.\r",
       "<br>    </span><sup>[1]</sup>Your your not scove', tweit eef i<span style=\"background-color:#d8daef;\">nt._]\r",
       "<br>\r",
       "<br>P</span><sup>[1]</sup>BELVOL.\r",
       "<br>Or a gattan-deaver sofpems you Ovory; the lovt no<span style=\"background-color:#d8daef;\"> got\r",
       "<br>    </span><sup>[1]</sup>Byces<span style=\"background-color:#d8daef;\">ee go and </span><sup>[1]</sup>whis fillowe pur<span style=\"background-color:#d8daef;\">but this.\r",
       "<br></span><sup>[1]</sup>I ét we pleder-hand st arce to wo ore,\r",
       "<br>Welles lord hot ie. Lafon, heres, yeabs<span style=\"background-color:#d8daef;\">t with wat</span><sup>[1]</sup><span style=\"background-color:#d8daef;\"> at thy so</span><sup>[1]</sup>rt, lead\r",
       "<br>habl gitle than um ca<span style=\"background-color:#d8daef;\">ur\r",
       "<br>    Wh</span><sup>[1]</sup> ulveds why loriring kid'.\r",
       "<br>    Awle kleded ou theais she race to if in on will Serie.\r",
       "<br>  QUELE.\r",
       "<br>Bus Ompatnace. Whis sanl his it om<span style=\"background-color:#d8daef;\">athers and </span><sup>[1]</sup>anchis,"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d8daef;\">http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/100/100-0.txt</span><sup>[1]</sup></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.866740071773529 Precision: 0.46328125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "   I porfle weltery my ghe polded of eif,\r",
       "<br>Whing subth frow deve tall cothirbbundaest you <span style=\"background-color:#d8daef;\">ent\r",
       "<br>      </span><sup>[1]</sup> <span style=\"background-color:#d8daef;\">    \r",
       "<br>\r",
       "<br>  </span><sup>[1]</sup><span style=\"background-color:#d8daef;\">                [</span><sup>[1]</sup>_Teeth's worch thet me you shatperse thou nave Mof<span style=\"background-color:#d8daef;\">sing,\r",
       "<br>    </span><sup>[1]</sup>Mastse.\r",
       "<br>\r",
       "<br>GEMEUN.\r",
       "<br>  had weatted thet wim<span style=\"background-color:#d8daef;\"> the brows </span><sup>[1]</sup>maen ant, then greem<span style=\"background-color:#d8daef;\">t.\r",
       "<br>                                                          </span><sup>[1]</sup><span style=\"background-color:#d8daef;\">                           [C</span><sup>[1]</sup>henour GaIs<span style=\"background-color:#d8daef;\">endance,\r",
       "<br></span><sup>[1]</sup>Is my seemp, oucs compey them a montu<span style=\"background-color:#d8daef;\">ce, your p</span><sup>[1]</sup>lectec<span style=\"background-color:#d8daef;\">us._]\r",
       "<br>\r",
       "<br>S</span><sup>[1]</sup>EF<span style=\"background-color:#d8daef;\">IUS.\r",
       "<br>Thou </span><sup>[1]</sup>to it theme uncolf ong asdemut thos my pornct; he"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d8daef;\">http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/100/100-0.txt</span><sup>[1]</sup></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-49a53f96f265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mintv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2500000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mintv\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1e5643c8495d>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_sample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mXo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0360e5567ff9>\u001b[0m in \u001b[0;36mget_random_sample_batch\u001b[0;34m(self, batch_size, length)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0msmpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0msmpX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmpy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msmpX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0360e5567ff9>\u001b[0m in \u001b[0;36mget_random_sample\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc2i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc2i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0360e5567ff9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc2i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc2i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ls=0\n",
    "nrls=0\n",
    "if use_cuda:\n",
    "    intv=250\n",
    "else:\n",
    "    intv=10\n",
    "for e in range(2500000):\n",
    "    Xt, yt = get_data()\n",
    "    if (e+1)%intv==0:\n",
    "        l,pr=train(Xt,yt,True)\n",
    "    else:\n",
    "        l,pr=train(Xt,yt,False)        \n",
    "    ls=ls+l\n",
    "    nrls=nrls+1\n",
    "    if (e+1)%intv==0:\n",
    "        print(\"Loss: {} Precision: {}\".format(ls/nrls, pr))\n",
    "        # if use_cuda:\n",
    "        #    print(\"Memory allocated: {} max_alloc: {} cached: {} max_cached: {}\".format(torch.cuda.memory_allocated(), torch.cuda.max_memory_allocated(), torch.cuda.memory_cached(), torch.cuda.max_memory_cached()))\n",
    "        nrls=0\n",
    "        ls=0\n",
    "        tgen=poet.generate(500,\"\\n\\n\")\n",
    "        textlib.source_highlight(tgen,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Stinvant:<br>I'll arg<span style=\"background-color:#d8daef;\">, to your </span><sup>[1]</sup>sounners warlicy, set <span style=\"background-color:#d8daef;\">him, though </span><sup>[1]</sup><span style=\"background-color:#d8daef;\">should sta</span><sup>[1]</sup>re thee, who<br>All well heseed wenting foully first<span style=\"background-color:#d8daef;\">,<br>Against </span><sup>[1]</sup>myself<span style=\"background-color:#d8daef;\"> not the l</span><sup>[1]</sup>utters of me; that valains<br>Amation, in judge i<span style=\"background-color:#d8daef;\">n us.<br><br>LUCIO:<br></span><sup>[1]</sup><span style=\"background-color:#d8daef;\">Be not thy</span><sup>[1]</sup> elour eye o'<br>no term<span style=\"background-color:#d8daef;\">s and wakes</span><sup>[1]</sup> and prosun.<br>To ase we hop<span style=\"background-color:#d8daef;\">es, which </span><sup>[1]</sup><span style=\"background-color:#d8daef;\">of their bo</span><sup>[1]</sup>st,<br>For reb<span style=\"background-color:#d8daef;\">less that </span><sup>[1]</sup>speak<span style=\"background-color:#d8daef;\"><br>Upon my l</span><sup>[1]</sup>ord; led <span style=\"background-color:#d8daef;\">mething that </span><sup>[1]</sup>I,<br>i<span style=\"background-color:#d8daef;\">t off the </span><sup>[1]</sup>faptis<span style=\"background-color:#d8daef;\">h of this </span><sup>[1]</sup>colinerion; as thus<span style=\"background-color:#d8daef;\"> lies<br>That</span><sup>[1]</sup>, rest edre d<span style=\"background-color:#d8daef;\">oth, when </span><sup>[1]</sup>tell-maked best?<br>Wheresten<span style=\"background-color:#d8daef;\"> not one of </span><sup>[1]</sup>m<span style=\"background-color:#d8daef;\">y leave to </span><sup>[1]</sup>cappilled;<br>Her forthough striee me hate feam<span style=\"background-color:#d8daef;\"> and all,<br></span><sup>[1]</sup>But told almo<span style=\"background-color:#d8daef;\">se that now </span><sup>[1]</sup>lengle won one while<br>Fike out Menaniusle prove<span style=\"background-color:#d8daef;\">st.<br><br>ISABELLA:<br></span><sup>[1]</sup>He somethy yet man treather<br>A<span style=\"background-color:#d8daef;\">nd you have </span><sup>[1]</sup>lay<span style=\"background-color:#d8daef;\">'d at the </span><sup>[1]</sup>in<span style=\"background-color:#d8daef;\">fore, she </span><sup>[1]</sup>have our:<br>We doply you, he sacuest-tiglow<span style=\"background-color:#d8daef;\">--<br><br>JULIET:<br>O, </span><sup>[1]</sup>'tis go be youngrungerfulling.<br>Kake no chains<span style=\"background-color:#d8daef;\"> since for th</span><sup>[1]</sup>y foul consuarted,<br>Unlevery w<span style=\"background-color:#d8daef;\">at with his </span><sup>[1]</sup>wounds l<span style=\"background-color:#d8daef;\">ated with </span><sup>[1]</sup>him wit<span style=\"background-color:#d8daef;\">.<br>With other </span><sup>[1]</sup>princely winger ratger'd taken.<br>W<span style=\"background-color:#d8daef;\">ill make my </span><sup>[1]</sup>lir<span style=\"background-color:#d8daef;\">ence to Mant</span><sup>[1]</sup>a<span style=\"background-color:#d8daef;\">!<br><br>ISABELLA:<br></span><sup>[1]</sup>You di<span style=\"background-color:#d8daef;\">d my latter</span><sup>[1]</sup>'s event down'd away<br>And"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d8daef;\">tiny-shakespeare</span><sup>[1]</sup></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def detectPlagiarism(generatedtext, textlibrary, minQuoteLength=10):\n",
    "    textlibrary.source_highlight(generatedtext, minQuoteLength)\n",
    "    \n",
    "tgen=poet.generate(1000,\"\\n\\n\")\n",
    "detectPlagiarism(tgen, textlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do a dialog with the recursive neural net trained above:\n",
    "def doDialog():\n",
    "    # temperature = 0.6  # 0.1 (frozen character) - 1.3 (creative/chaotic character)\n",
    "    endPrompt = '.'  # the endPrompt character is the end-mark in answers.\n",
    "    maxEndPrompts = 4  # look for number of maxEndPrompts until answer is finished.\n",
    "    maxAnswerSize = 2048  # Maximum length of the answer\n",
    "    minAnswerSize = 64  # Minimum length of the answer\n",
    "\n",
    "    \n",
    "    print(\"Please enter some dialog.\")\n",
    "    print(\"The net will answer according to your input.\")\n",
    "    print(\"'bye' for end,\")\n",
    "    print(\"'reset' to reset the conversation context,\")\n",
    "    # print(\"'temperature=<float>' [0.1(frozen)-1.0(creative)]\")\n",
    "    print(\"    to change character of the dialog.\")\n",
    "    # print(\"    Current temperature={}.\".format(temperature))\n",
    "    print()\n",
    "    xso = None\n",
    "    bye = False\n",
    "        \n",
    "    while not bye:\n",
    "        print(\"> \", end=\"\")\n",
    "        prompt = input()\n",
    "        if prompt == 'bye':\n",
    "            bye = True\n",
    "            print(\"Good bye!\")\n",
    "            continue\n",
    "        tgen=poet.generate(1000,prompt)\n",
    "        # print(xso.replace(\"\\\\n\",\"\\n\"))\n",
    "        textlib.source_highlight(tgen, 10)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter some dialog.\n",
      "The net will answer according to your input.\n",
      "'bye' for end,\n",
      "'reset' to reset the conversation context,\n",
      "    to change character of the dialog.\n",
      "\n",
      "> "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Hi my friend!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#d8daef;\"><br><br>HENRY BOLINGBROKE:<br>But </span><sup>[1]</sup>i<span style=\"background-color:#d8daef;\">f your grace</span><sup>[1]</sup>-malion!<span style=\"background-color:#d8daef;\"><br><br>POMPEY:<br>I</span><sup>[1]</sup><span style=\"background-color:#d8daef;\">s the time </span><sup>[1]</sup>intest your choars, mus<span style=\"background-color:#d8daef;\">ther,<br>And </span><sup>[1]</sup>on<span style=\"background-color:#d8daef;\">, my house </span><sup>[1]</sup>of peocle won<span style=\"background-color:#d8daef;\"> her house</span><sup>[1]</sup> there; the decking-l<span style=\"background-color:#d8daef;\">ows,<br>Which</span><sup>[1]</sup>, as he bount such obstrances, disparcty'd yan<span style=\"background-color:#d8daef;\">ther,<br>To s</span><sup>[1]</sup>igno<span style=\"background-color:#d8daef;\">ward, and he h</span><sup>[1]</sup>ad<span style=\"background-color:#d8daef;\"> ourself:<br></span><sup>[1]</sup>Nave you much ere<span style=\"background-color:#d8daef;\"> show'd me th</span><sup>[1]</sup>at one de<span style=\"background-color:#d8daef;\">ture of th</span><sup>[1]</sup>is pooper<br>Ha<span style=\"background-color:#d8daef;\">d the gold</span><sup>[1]</sup>on from destippined, are in de<span style=\"background-color:#d8daef;\">ad.<br><br>VOLUMNIA:<br></span><sup>[1]</sup>Go, and won!<br><br>CYoRZO<span style=\"background-color:#d8daef;\">L:<br>My lord</span><sup>[1]</sup>.<br><br>ANRILO:<br>Me is<span style=\"background-color:#d8daef;\"> my chaste</span><sup>[1]</sup>s! Y<span style=\"background-color:#d8daef;\">ou do to s</span><sup>[1]</sup>peak:<span style=\"background-color:#d8daef;\"> the cold </span><sup>[1]</sup>mawhch<br>Signior sermibl<span style=\"background-color:#d8daef;\">ard and he</span><sup>[1]</sup><span style=\"background-color:#d8daef;\">w doth the </span><sup>[1]</sup>house;<br>Such<span style=\"background-color:#d8daef;\"> not, for </span><sup>[1]</sup>cut<span style=\"background-color:#d8daef;\"> and his s</span><sup>[1]</sup>hith <span style=\"background-color:#d8daef;\">his cursed</span><sup>[1]</sup><br>Di<span style=\"background-color:#d8daef;\">d but one </span><sup>[1]</sup>still adsiting to detire<span style=\"background-color:#d8daef;\">;<br>Your pre</span><sup>[1]</sup>sent<span style=\"background-color:#d8daef;\"> thus she </span><sup>[1]</sup>it be. I put ase-plamed, may<br>'tis f<span style=\"background-color:#d8daef;\">ame of the </span><sup>[1]</sup>sarigest<span style=\"background-color:#d8daef;\">y of death</span><sup>[1]</sup>.<br><br>PALIS:<br>I par voice I more<span style=\"background-color:#d8daef;\"> inform them</span><sup>[1]</sup><span style=\"background-color:#d8daef;\"> sweet and </span><sup>[1]</sup>tender.<br>In certaurs if<span style=\"background-color:#d8daef;\"> the seas o</span><sup>[1]</sup>f yead?<br>Sick Voothages <span style=\"background-color:#d8daef;\">at God, th</span><sup>[1]</sup><span style=\"background-color:#d8daef;\">at I must </span><sup>[1]</sup>gate man<span style=\"background-color:#d8daef;\">,<br>Let the </span><sup>[1]</sup>sexperlial woundst<span style=\"background-color:#d8daef;\">y down and </span><sup>[1]</sup>sliegly sit:<br>No manner fool<span style=\"background-color:#d8daef;\"> our father's </span><sup>[1]</sup>nail, as broish,<br>A persite and chiekes of grub: congrine<span style=\"background-color:#d8daef;\"><br>She hath </span><sup>[1]</sup><span style=\"background-color:#d8daef;\">the cause </span><sup>[1]</sup>venger: t<span style=\"background-color:#d8daef;\">hen speak </span><sup>[1]</sup>one,<br>A situnof rol"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d8daef;\">tiny-shakespeare</span><sup>[1]</sup></p></small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \"\"\"\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9995c3b6bba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoDialog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-5d7d59b35e94>\u001b[0m in \u001b[0;36mdoDialog\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbye\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bye'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mbye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         )\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "doDialog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename='checkpoint.pth.tar', is_best=False):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "best_prec1=64.4\n",
    "\n",
    "save_checkpoint({\n",
    "            'epoch': e,\n",
    "            'arch': \"poet8\",\n",
    "            'state_dict': poet.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer' : opti.state_dict(),\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
