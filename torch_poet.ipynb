{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of torch_poet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/domschl/torch-poet/blob/master/torch_poet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "28i44jSzUlon",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from enum import Enum\n",
        "import re\n",
        "import time\n",
        "import logging\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "try:\n",
        "    from urllib.request import urlopen  # Py3\n",
        "except:\n",
        "    print(\"This notebook requires Python 3.\")\n",
        "try:\n",
        "    import pathlib\n",
        "except:\n",
        "    print(\"At least python 3.5 is needed.\")\n",
        "    \n",
        "try: # Colab instance?\n",
        "    from google.colab import drive\n",
        "except: # Not? ignore.\n",
        "    pass\n",
        "\n",
        "from IPython.core.display import display, HTML"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eE-jm072kOKv"
      },
      "source": [
        "# 0. System configuration\n",
        "\n",
        "This notebook can either run on a local jupyter server, or on google cloud.\n",
        "If a GPU is available, it will be used for training (if `force_cpu` is not set to `True`).\n",
        "\n",
        "By default snapshots of the trained net are stored locally for jupyter instances, and on user's google drive for Google Colab instances. The snapshots allow the restart of training or inference at any time, e.g. after the Colab session was terminated.\n",
        "\n",
        "Similarily, the text corpora that are used for training, can be cached on drive or locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HVyGr-BCiJlR",
        "colab": {}
      },
      "source": [
        "# force_cpu=True: use CPU for training, even if a GPU is available.\n",
        "#    Note: inference uses CPU always, because that is faster.\n",
        "force_cpu=False\n",
        "\n",
        "# Define where snapshots of training data are stored:\n",
        "colab_google_drive_snapshots=True\n",
        "\n",
        "# Define if training data (the texts downloaded from internet) are cached:\n",
        "colab_google_drive_data_cache=True  # In colab mode cache to google drive\n",
        "local_jupyter_data_cache=True       # In local jupyter mode cache to local path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ply0tFmz4O1E",
        "colab": {}
      },
      "source": [
        "is_colab_notebook = 'google.colab' in sys.modules\n",
        "torch_version = torch.__version__\n",
        "\n",
        "if torch.cuda.is_available() and force_cpu is not True:\n",
        "    device='cuda'\n",
        "    use_cuda = True\n",
        "    print(f\"PyTorch {torch_version}, running on GPU\")\n",
        "    if is_colab_notebook:\n",
        "        card = !nvidia-smi\n",
        "        if len(card)>=8:\n",
        "            try:\n",
        "                gpu_type=card[7][6:25]\n",
        "                gpu_memory=card[8][33:54]\n",
        "                print(f\"Colab GPU: {gpu_type}, GPU Memory: {gpu_memory}\")\n",
        "            except Exception as e:\n",
        "                pass\n",
        "else:\n",
        "    device='cpu'\n",
        "    use_cuda = False\n",
        "    print(f\"{torch_version}, running on CPU\")\n",
        "    if colab_notebook:\n",
        "        print(\"Note: on Google Colab, make sure to select:\")\n",
        "        print(\"      Runtime / Change Runtime Type / Hardware accelerator: GPU\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kTRmAT1f4O1I",
        "colab": {}
      },
      "source": [
        "if is_colab_notebook:\n",
        "    if colab_google_drive_snapshots:\n",
        "        mountpoint='/content/drive'\n",
        "        root_path='/content/drive/My Drive'\n",
        "        if not os.path.exists(root_path):\n",
        "            drive.mount(mountpoint)\n",
        "        if not os.path.exists(root_path):\n",
        "            print(\"Something went wrong with Google Drive access. Cannot save snapshots to GD.\")\n",
        "            colab_google_drive_snapshots=False\n",
        "    else:\n",
        "        print(\"Since google drive snapshots are not active, training data will be lost as soon as the Colab session terminates!\")\n",
        "        print(\"Set `colab_google_drive_snapshots` to `True` to make training data persistent.\")\n",
        "else:\n",
        "    root_path='.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nlMMykJxsJcv",
        "colab": {}
      },
      "source": [
        "def one_hot(p, dim):\n",
        "    o=np.zeros(p.shape+(dim,), dtype=int)\n",
        "    for y in range(p.shape[0]):\n",
        "        for x in range(p.shape[1]):\n",
        "            o[y,x,p[y,x]]=1\n",
        "    return o"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JoutSg5IUlot"
      },
      "source": [
        "# 1. Text data collection\n",
        "\n",
        "**Important note:** the following `project_name` determines the root directory for training data and model snapshots, so it should be changed whenever datasets of model configurations are changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuuvAPeIjtp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_name = \"philosophers_lang_eng\"\n",
        "project_description = \"A model trained on several books of philosophers in English language.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPD_j8qRjtp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if is_colab_notebook:\n",
        "    if colab_google_drive_data_cache is True:\n",
        "        data_cache_path=os.path.join(root_path,f\"Colab Notebooks/{project_name}/Data\")\n",
        "    else:\n",
        "        data_cache_path=None\n",
        "else:\n",
        "    if local_jupyter_data_cache is True:\n",
        "        data_cache_path=os.path.join(root_path,f\"{project_name}/Data\")\n",
        "    else:\n",
        "        data_cache_path=None\n",
        "\n",
        "if data_cache_path is not None:\n",
        "    pathlib.Path(data_cache_path).mkdir(parents=True, exist_ok=True)\n",
        "    if not os.path.exists(data_cache_path):\n",
        "        print(\"ERROR, the cache directory does not exist. This will fail.\")\n",
        "            \n",
        "def get_cache_name(cache_path, author, title):\n",
        "    if cache_path is None:\n",
        "        return None\n",
        "    cname=f\"{author} - {title}.txt\"\n",
        "    cname=cname.replace('?','_')  # Gutenberg index is pre-Unicode-mess and some titles contain '?' for bad conversions.\n",
        "    cache_filepath=os.path.join(cache_path, cname)\n",
        "    return cache_filepath"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPkfXQbGjtp_",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Project Gutenberg data source\n",
        "\n",
        "Search, filter, clean and download books from Project Gutenberg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz_LqFccjtqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HELQbmZwjtqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GutenbergLib:\n",
        "    \"\"\" A fuzzy, lightweight library to access, search and filter Project Gutenberg resources \"\"\"\n",
        "    def __init__(self, root_url=\"http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg\", cache_dir=\"gutenberg\"):\n",
        "        \"\"\" GutenbergLib by default uses a mirror's root URL\n",
        "        \n",
        "        root_url -- url of Project Gutenberg or any mirror URL.\n",
        "        cache_dir -- path to a directory that will be used to cache the Gutenberg index and already downloaded texts\n",
        "        \"\"\"\n",
        "        self.log = logging.getLogger('GutenbergLib')\n",
        "        self.root_url = root_url\n",
        "        self.index=None\n",
        "        self.NEAR=2048\n",
        "        try:\n",
        "            if not os.path.exists(cache_dir):\n",
        "                os.makedirs(cache_dir)\n",
        "            self.cache_dir=cache_dir\n",
        "        except Exception as e:\n",
        "            self.cache_dir=None\n",
        "            self.log.error(f\"Failed to create cache directory {cache_dir}, {e}\")\n",
        "\n",
        "    def _parse_record(self,record,verbose=True):\n",
        "        \"\"\" internal function to recreate some consistent record information from near-freestyle text \"\"\"\n",
        "        rl=record.split('\\n')\n",
        "        white=str(chr(160))+str(chr(9))+\" \" # non-breaking space, TAB, and space\n",
        "        ebook_no=\"\"\n",
        "        while len(rl[0])>0 and rl[0][-1] in white:\n",
        "            rl[0]=rl[0][:-1]\n",
        "        while len(rl[0])>0 and not rl[0][-1] in white:\n",
        "            ebook_no=rl[0][-1]+ebook_no\n",
        "            rl[0]=rl[0][:-1]\n",
        "        while len(rl[0])>0 and rl[0][-1] in white:\n",
        "            rl[0]=rl[0][:-1]\n",
        "        \n",
        "        # Sanity check\n",
        "        try:\n",
        "            fa=re.findall(ebook_no,\"\\A[0-9]+[A-C]\\Z\")\n",
        "        except Exception as e:\n",
        "            fa=None\n",
        "            if verbose is True:\n",
        "                self.log.debug(f\"Failed to apply regex on >{ebook_no}<\")\n",
        "            \n",
        "        if len(rl[0])<5 or fa==None or len(ebook_no)>7:\n",
        "            if verbose is True:\n",
        "                print(\"-------------------------------------\")\n",
        "                print(record)\n",
        "                print(\"- - - - - - - - - - - - - - - - - - -\")\n",
        "                print(f\"Dodgy record: {rl[0]}\")\n",
        "                print(f\"    ebook-id:  >{ebook_no}<\")\n",
        "            return None\n",
        "        \n",
        "        for i in range(len(rl)):\n",
        "            rl[i]=rl[i].strip()\n",
        "            \n",
        "        p=0\n",
        "        while p<len(rl)-1:\n",
        "            if len(rl[p+1])==0:\n",
        "                print(f\"Invalid rec: {record}\")\n",
        "                p+=1\n",
        "            else:\n",
        "                if rl[p+1][0]!=\"[\":\n",
        "                    rl[p]+=\" \"+rl[p+1]\n",
        "                    del rl[p+1]\n",
        "                    if rl[p][-1]==']':\n",
        "                        p+=1\n",
        "                else:\n",
        "                    p+=1\n",
        "        \n",
        "        rec={}\n",
        "        l0=rl[0].split(\", by \")\n",
        "        rec['title']=l0[0]\n",
        "        rec['ebook_id']=ebook_no\n",
        "        # if len(l0)>2:\n",
        "        #    print(f\"Chaos title: {rl[0]}\")\n",
        "        if len(l0)>1:\n",
        "            rec['author']=l0[-1]\n",
        "        for r in rl[1:]:\n",
        "            if r[0]!='[' or r[-1]!=']':\n",
        "                if r[0]=='[':\n",
        "                    ind=r.rfind(']')\n",
        "                    if ind != -1:\n",
        "                        # print(f\"Garbage trail {r}\")\n",
        "                        r=r[:ind+1]\n",
        "                        # print(f\"Fixed: {r}\")\n",
        "                    else:\n",
        "                        # print(f\"Missing closing ] {r}\")\n",
        "                        r+=']'\n",
        "                        # print(f\"Fixed: {r}\")\n",
        "            if r[0]=='[' and r[-1]==']':\n",
        "                r=r[1:-1]\n",
        "                i1=r.find(':')\n",
        "                if i1==-1:\n",
        "                    r=r.replace(\"Author a.k.a.\",\"Author a.k.a.:\")\n",
        "                    i1=r.find(':')\n",
        "                if i1!=-1:\n",
        "                    i2=r[i1:].find(' ')+i1\n",
        "                else:\n",
        "                    i2=-1\n",
        "                if i1==-1 and i2==-1:\n",
        "                    pass\n",
        "                    # print(f\"Invalid attribut in {rl}::{r}\")\n",
        "                else:\n",
        "                    if i2-i1==1:\n",
        "                        key=r[:i1]\n",
        "                        val=r[i2+1:]\n",
        "                        if '[' in key or ']' in key or '[' in val or ']' in val or len(key)>15:\n",
        "                            pass\n",
        "                            # print(\"messy key/val\")\n",
        "                        else:\n",
        "                            rec[key.strip().lower()]=val.strip()\n",
        "                    else:\n",
        "                        pass\n",
        "                        # print(f\"Bad attribute name terminator, missing ': ' {r}\")\n",
        "            else:\n",
        "                pass\n",
        "                # print(f\"Invalid attribut in {rl}::{r}\")\n",
        "        if len(rec)>1:\n",
        "            if \"language\" not in rec.keys():\n",
        "                rec[\"language\"]=\"English\"\n",
        "        return rec\n",
        "        \n",
        "    def _parse_index(self, lines):\n",
        "        \"\"\" internal function to parse the fuzzy text-based Gutenberg table of content \"\"\"\n",
        "        class State(Enum):\n",
        "            NONE=1,\n",
        "            SYNC_START=2,\n",
        "            SYNC_REC=3,\n",
        "            END=5\n",
        "    \n",
        "        white=str(chr(160))+str(chr(9))+\" \" # non-breaking space, TAB, and space\n",
        "        state=State.NONE\n",
        "        start_token=\"~ ~ ~ ~\"\n",
        "        stop_token=[\"=====\"]\n",
        "        end_token=\"<==End\"\n",
        "        ignore_headers=[\"TITLE and AUTHOR\"]\n",
        "        ignore_content=[\"Not in the Posted Archives\",\"human-read audio ebooks\", \"Audio:\"]\n",
        "        empty_lines=0\n",
        "        records=[]\n",
        "        for line in lines:\n",
        "            if line[:len(end_token)]==end_token:\n",
        "                state=State.END\n",
        "                break\n",
        "\n",
        "            if state==State.NONE:\n",
        "                if line[:len(start_token)]==start_token:\n",
        "                    state=State.SYNC_START\n",
        "                    empty_lines=0\n",
        "                    continue\n",
        "            if state==State.SYNC_START:\n",
        "                if len(line.strip())==0:\n",
        "                    empty_lines+=1\n",
        "                    if empty_lines>1:\n",
        "                        state=State.NONE\n",
        "                        continue\n",
        "                else:\n",
        "                    stopped=False\n",
        "                    for stop in stop_token:\n",
        "                        if line[:len(stop)]==stop:\n",
        "                            stopped=True\n",
        "                            break\n",
        "                    if stopped is True:\n",
        "                        state=State.NONE\n",
        "                        empty_lines=0\n",
        "                        continue\n",
        "                    ignore=False\n",
        "                    for header in ignore_headers:\n",
        "                        if line[:len(header)]==header:\n",
        "                            empty_lines=0\n",
        "                            ignore=True\n",
        "                    for token in ignore_content:\n",
        "                        if token in line:\n",
        "                            empty_lines=0\n",
        "                            ignore=True\n",
        "                    if ignore is True:\n",
        "                        continue\n",
        "                    rec=line\n",
        "                    state=State.SYNC_REC\n",
        "                    continue\n",
        "            if state==State.SYNC_REC:\n",
        "                if len(line.strip())==0 or line[0] not in white:\n",
        "                    if len(records)<10:\n",
        "                        parsed_rec=self._parse_record(rec, verbose=True)\n",
        "                    else:\n",
        "                        parsed_rec=self._parse_record(rec, verbose=False)\n",
        "                        \n",
        "                    if parsed_rec is not None:\n",
        "                        records.append(parsed_rec)\n",
        "                    empty_lines=1\n",
        "                    if len(line.strip())==0:\n",
        "                        state=State.SYNC_START\n",
        "                        continue\n",
        "                    else:\n",
        "                        rec=line\n",
        "                        continue\n",
        "                rec=rec+\"\\n\"+line\n",
        "        return records\n",
        "                    \n",
        "    def load_index(self, cache=True, cache_expire_days=30):\n",
        "        \"\"\" This function loads the Gutenberg record index, either from cache, or from a website\n",
        "        \n",
        "        cache -- default True, use the cache directory to cache both index and text files. Index\n",
        "        expires after cache_expire_days, text files never expire. Should *NOT* be set to False\n",
        "        in order to prevent unnecessary re-downloading.\n",
        "        cache_expire_days -- Number of days after which the index is re-downloaded.\"\"\"\n",
        "        raw_index=None\n",
        "        if self.cache_dir is None:\n",
        "            self.log.error(\"Cannot cache library index, no valid cache directory.\")\n",
        "            return False\n",
        "        ts_file=os.path.join(self.cache_dir,\"timestamp\")\n",
        "        cache_file=os.path.join(self.cache_dir,\"gutenberg_index\")\n",
        "        expired=True\n",
        "        read_from_cache=False\n",
        "        if os.path.isfile(ts_file) and os.path.isfile(cache_file):\n",
        "            try:\n",
        "                with open(ts_file,'r') as f:\n",
        "                    ts=float(f.read())\n",
        "                if time.time()-ts<cache_expire_days*24*3600:\n",
        "                    expired=False\n",
        "                    read_from_cache = True\n",
        "                    self.log.debug(\"Cache timestamp read.\")\n",
        "                else:\n",
        "                    self.log.debug(\"Cache for index is expired, reloading from web.\")\n",
        "            except:\n",
        "                self.log.debug(\"Failed to read cache timestamp, reloading from web.\")\n",
        "        if expired is False and os.path.isfile(cache_file):\n",
        "            try:\n",
        "                with open(cache_file,'r') as f:\n",
        "                    raw_index=f.read()\n",
        "                    self.log.info(f\"Gutenberg index read from {cache_file}\")\n",
        "            except:\n",
        "                expired=True\n",
        "                self.log.debug(\"Failed to read cached index, reloading from web.\")\n",
        "        if expired is True:\n",
        "            index_url=self.root_url+\"/GUTINDEX.ALL\"\n",
        "            try:\n",
        "                raw_index = urlopen(index_url).read().decode('utf-8')\n",
        "                if raw_index[0]=='\\ufeff':  # Ignore BOM\n",
        "                    raw_index=raw_index[1:]\n",
        "                raw_index=raw_index.replace('\\r','')\n",
        "                self.log.info(f\"Gutenberg index read from {index_url}\")\n",
        "            except Exception as e:\n",
        "                self.log.error(f\"Failed to download Gutenberg index from {index_rul}, {e}\")\n",
        "                return False\n",
        "        if cache is True and read_from_cache is False:\n",
        "            try:\n",
        "                with open(ts_file,'w') as f:\n",
        "                    f.write(str(time.time()))\n",
        "                    self.log.debug(\"Wrote read cache timestamp.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to write cache timestamp to {ts_file}, {e}\")\n",
        "            try:\n",
        "                with open(cache_file,'w') as f:\n",
        "                    f.write(raw_index)\n",
        "                    self.log.debug(\"Wrote read cached index.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to write cached index to {cache_file}, {e}\")\n",
        "        lines=raw_index.split('\\n')\n",
        "        self.records=self._parse_index(lines)\n",
        "    \n",
        "    def load_book(self, ebook_id):\n",
        "        \"\"\" get text of an ebook from Gutenberg by ebook_id \n",
        "        \n",
        "        ebook_id -- Gutenberg id\n",
        "        \"\"\"\n",
        "        if ebook_id is None or len(ebook_id)==0:\n",
        "            return None\n",
        "        if ebook_id[-1]=='C':\n",
        "            ebook_id=ebook_id[:-1]\n",
        "        path_stub=\"\"\n",
        "        \n",
        "        for i in range(len(ebook_id)-1):\n",
        "            path_stub+=\"/\"+ebook_id[i]\n",
        "        path_stub+=\"/\"+ebook_id+\"/\"\n",
        "        filenames=[(ebook_id+\"-0.txt\",'utf-8'), (ebook_id+\".txt\",'utf-8'), (ebook_id+\"-8.txt\",\"latin1\")]\n",
        "        cache_name=ebook_id+\".txt\"\n",
        "        if self.cache_dir is not None:\n",
        "            cache_file=os.path.join(self.cache_dir,cache_name)\n",
        "            if os.path.isfile(cache_file):\n",
        "                try:\n",
        "                    with open(cache_file,'r') as f:\n",
        "                        data=f.read()\n",
        "                        self.log.info(f\"Book read from cache at {cache_file}\")\n",
        "                        return data\n",
        "                except Exception as e:\n",
        "                    self.log.error(f\"Failed to read cached file {cache_file}\")\n",
        "        data=None\n",
        "        for filename, encoding in filenames:\n",
        "            file_url=self.root_url+path_stub+filename\n",
        "            try:\n",
        "                data = urlopen(file_url).read().decode(encoding)\n",
        "                self.log.info(f\"Book downloaded from {file_url}\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                self.log.debug(f\"URL-Download failed: {file_url}, {e}\")\n",
        "                pass\n",
        "        if data is None:\n",
        "            self.log.error(f\"Failed to download {filenames}\")\n",
        "            return None\n",
        "        if self.cache_dir is not None:\n",
        "            try:\n",
        "                with open(cache_file,'w') as f:\n",
        "                    f.write(data)\n",
        "            except:\n",
        "                self.log.error(f\"Failed to cache file {cache_file}\")\n",
        "        return data\n",
        "    \n",
        "    def filter_text(self, book_text):\n",
        "        \"\"\" Heuristically remove header and trailer texts not part of the actual book \n",
        "        \"\"\"\n",
        "        start_tokens=[\"*** START OF THIS PROJECT\", \"E-text prepared by\", \"This book was generously provided by the \"]\n",
        "        near_start_tokens=[\"produced by \", \"Produced by \", \"Transcriber's Note\", \"Transcriber's note:\", \"Anmerkungen zur Tanskription\"]\n",
        "        end_tokens=[\"End of the Project Gutenberg\", \"*** END OF THIS PROJECT\", \"***END OF THE PROJECT GUTENBER\",\n",
        "                   \"Ende dieses Projekt Gutenberg\", \"End of Project Gutenberg\", \"Transcriber's Note\"]\n",
        "        blen=len(book_text)\n",
        "        \n",
        "        pstart=0\n",
        "        for token in start_tokens:\n",
        "            pos=book_text.find(token)\n",
        "            if pos > pstart:\n",
        "                pstart = pos\n",
        "                self.log.debug(f\"Start-token [{token}] found at position {pos}\")\n",
        "        if pstart>0:\n",
        "            pos=book_text[pstart:].find(\"\\n\\n\")\n",
        "            if pos>=0 and pos <= self.NEAR:\n",
        "                pos += pstart\n",
        "                while book_text[pos]=='\\n':\n",
        "                    pos += 1  # eof?!\n",
        "                pstart=pos\n",
        "        if pstart>blen/2:\n",
        "            self.log.warning(\"Preamble is taking more than half of the book!\")\n",
        "        new_book=book_text[pstart:]\n",
        "        \n",
        "        xpos=-1\n",
        "        for token in near_start_tokens:\n",
        "            pos=new_book.find(token)\n",
        "            if pos>=0 and pos<=self.NEAR:\n",
        "                self.log.debug(f\"Near-Start-token [{token}] found at position {pos}\")\n",
        "                if pos>xpos:\n",
        "                    xpos=pos\n",
        "        if xpos > -1:\n",
        "            pos2=new_book[xpos:].find(\"\\n\\n\")\n",
        "            self.log.debug(f\"Trying extra skipping for {pos2}...\")\n",
        "            if pos2<=self.NEAR and pos2>0:\n",
        "                self.log.debug(\"Trying extra skipping (2)...\")\n",
        "                while new_book[xpos+pos2]=='\\n':\n",
        "                    pos2 += 1\n",
        "                new_book=new_book[xpos+pos2:]\n",
        "                self.log.debug(f\"Additionally shortened start by {xpos+pos2} chars\")\n",
        "        \n",
        "        pend=len(new_book)\n",
        "        for token in end_tokens:\n",
        "            pos=new_book.find(token)\n",
        "            if pos!=-1 and pos < pend:\n",
        "                self.log.debug(f\"End-token [{token}] found at pos {pos}\")\n",
        "                pend = pos\n",
        "        if pend<len(new_book):\n",
        "            pos=new_book[:pend].rfind(\"\\n\\n\")\n",
        "            if pos>0:\n",
        "                while new_book[pos]=='\\n':\n",
        "                    pos -= 1  # eof?!\n",
        "                pend=pos+1\n",
        "        else:\n",
        "            self.log.debug(\"No end token found!\")\n",
        "        if pend<len(new_book)/2:\n",
        "            self.log.warning(\"End-text is taking more than half of the book!\")\n",
        "        new_book=new_book[:pend]\n",
        "        return new_book\n",
        "        \n",
        "    def find_keywords(self,*search_keys):\n",
        "        \"\"\" Search of an arbitrary number of keywords in a book record\n",
        "        \n",
        "        returns -- list of records that contain all keywords in any field. \"\"\"\n",
        "        frecs=[]\n",
        "        for rec in self.records:\n",
        "            found=True\n",
        "            for sk in search_keys:\n",
        "                subkey=False\n",
        "                for key in rec.keys():\n",
        "                    if sk.lower() in key.lower() or sk.lower() in rec[key].lower():\n",
        "                        subkey=True\n",
        "                        break\n",
        "                if subkey is False:\n",
        "                    found=False\n",
        "                    break\n",
        "            if found is True:\n",
        "                frecs += [rec]\n",
        "        return frecs\n",
        "    \n",
        "    def search(self, search_dict):\n",
        "        \"\"\" Search for book record with key specific key values\n",
        "        For a list of valid keys, use `get_record_keys()`\n",
        "        Standard keys are:\n",
        "        ebook_id, author, language, title\n",
        "        example: search({\"title\": [\"philosoph\",\"phenomen\",\"physic\",\"hermeneu\",\"logic\"], \"language\":\"english\"})\n",
        "        Find all books whose titles contain at least one the keywords, language english. Search keys can either be\n",
        "        search for a single keyword (e.g. english), or an array of keywords. \n",
        "        returns -- list of records \"\"\"\n",
        "        frecs=[]\n",
        "        for rec in self.records:\n",
        "            found=True\n",
        "            for sk in search_dict:\n",
        "                if sk not in rec:\n",
        "                    found=False\n",
        "                    break\n",
        "                else:\n",
        "                    skl=search_dict[sk]\n",
        "                    if not isinstance(skl,list):\n",
        "                        skl=[skl]\n",
        "                    nf=0\n",
        "                    for skli in skl:\n",
        "                        if skli.lower() in rec[sk].lower():\n",
        "                            nf=nf+1\n",
        "                    if nf==0:\n",
        "                        found=False\n",
        "                        break\n",
        "            if found is True:\n",
        "                frecs += [rec]\n",
        "        return frecs\n",
        "        \n",
        "    \n",
        "    def get_record_keys(self):\n",
        "        \"\"\" Get a list of all keys that are used within records. Standard keys are:\n",
        "        ebook_id, author, language, title\n",
        "        \n",
        "        returns -- list of all different keys that are somehow used.\"\"\"\n",
        "        rks=[]\n",
        "        for r in self.records:\n",
        "            rks=set(list(rks) + list(r.keys()))\n",
        "        return rks\n",
        "\n",
        "    def get_unique_record_values(self, key):\n",
        "        \"\"\" Get a list of all unique values a given keys has for all records.\n",
        "        get_unique_records_values('language') returns all languages in Gutenberg.\"\"\"\n",
        "        uv=[]\n",
        "        if key not in self.get_record_keys():\n",
        "            print(f\"{key} is not a key used in any record!\")\n",
        "            return None\n",
        "        for r in self.records:\n",
        "            if key in r:\n",
        "                uv=set(list(uv)+[r[key]])\n",
        "        uv=sorted(uv)\n",
        "        return uv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3C1yExTjtqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the list of available books on Gutenberg.\n",
        "gbl=GutenbergLib(cache_dir=os.path.join(root_path, 'gutenberg_cache'))\n",
        "gbl.load_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrI3xSK7jtqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample searches\n",
        "search_specs=[\n",
        "    {\"title\": [\"love\", \"hate\", \"emotion\", \"drama\"], \"language\": [\"english\"]},\n",
        "    {\"author\": [\"brontë\",\"Jane Austen\", \"Woolf\", \"goethe\", \"kant\"], \"language\": [\"english\", \"german\"]},\n",
        "    {\"title\": [\"philosoph\", \"physic\", \"phenomen\", \"logic\"], \"language\": [\"english\"]},\n",
        "]\n",
        "for search_spec in search_specs:\n",
        "    book_list=gbl.search(search_spec)\n",
        "    print(f\"{len(book_list)} matching books found with search {search_spec}.\")\n",
        "# a search spec can be used by the following text library as datasource, it will automatically download, filter and prepare the content of the books requested."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqKMN8nLjtqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_libdesc(project_name, description, cache_path, book_list):\n",
        "    libdesc={\"name\": project_name, \"description\": description, \"lib\": []}\n",
        "    if cache_path is None or not os.path.exists(cache_path):\n",
        "        print(f\"A valid cache {cache_path} is needed!\")\n",
        "        return None\n",
        "    for book_entry in book_list:\n",
        "        try:\n",
        "            book_raw_content=gbl.load_book(book_entry['ebook_id'])\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download ebook_id {book_entry}, {e}\")\n",
        "            continue\n",
        "        if book_raw_content is not None:\n",
        "            try:\n",
        "                book_text=gbl.filter_text(book_raw_content)\n",
        "            except Exception as e:\n",
        "                print(f\"Internal error when filtering {book_entry}, {e}\")\n",
        "                continue\n",
        "            filename=get_cache_name(cache_path, book_entry['author'], book_entry['title'])\n",
        "            try:\n",
        "                with open(filename,'w') as f:\n",
        "                    f.write(book_text)\n",
        "                    print(f\"Cached {filename}\")\n",
        "                    libdesc[\"lib\"].append((filename, book_entry['author'], book_entry['title']))\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to cache {filename}\", {e})\n",
        "    return libdesc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQo6nTsPjtqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "book_list=gbl.search({\"author\": [\"platon\", \"descartes\", \"john locke\", \"david hume\", \"kant\", \"schopenhauer\", \"leibniz\", \"kierkegaard\", \"hegel\", \"nietzsche\", \"heidegger\", \"fichte\"], \"language\": [\"english\"]})\n",
        "print(f\"{len(book_list)} books found.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnYGn0LylSyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "book_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm97yp2ijtqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will download the books! make sure it's a reasonable number of books\n",
        "libdesc=create_libdesc(project_name, project_description, data_cache_path, book_list)\n",
        "\n",
        "with open(os.path.join(data_cache_path,'libdesc.json'),'w') as f:\n",
        "    json.dump(libdesc,f,indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF4CGmsbjtqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "libdesc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aXqlcaNajtqb"
      },
      "source": [
        "## 1.2 Text library\n",
        "\n",
        "`TextLibrary` class: text library for training, encoding, batch generation,\n",
        "and formatted source display. It read some books from Project Gutenberg\n",
        "and supports creation of training batches. The output functions support\n",
        "highlighting to allow to compare generated texts with the actual sources\n",
        "to help to identify identical (memorized) parts of a given length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MzXrUVe-4O1N",
        "colab": {}
      },
      "source": [
        "use_dark_mode=False  # Set to false for white background"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7pMoAJ-SVDm2",
        "colab": {}
      },
      "source": [
        "class TextLibrary:\n",
        "    def __init__(self, descriptors, text_data_cache_directory=None, max=100000000):\n",
        "        self.descriptors = descriptors\n",
        "        self.data = ''\n",
        "        self.cache_dir=text_data_cache_directory\n",
        "        self.files = []\n",
        "        self.c2i = {}\n",
        "        self.i2c = {}\n",
        "        index = 1\n",
        "        for descriptor, author, title in descriptors:\n",
        "            fd = {}\n",
        "            cache_name=get_cache_name(self.cache_dir, author, title)\n",
        "            if os.path.exists(cache_name):\n",
        "                is_cached=True\n",
        "            else:\n",
        "                is_cached=False\n",
        "            valid=False\n",
        "            if descriptor[:4] == 'http' and is_cached is False:\n",
        "                try:\n",
        "                    print(f\"Downloading {cache_name}\")\n",
        "                    dat = urlopen(descriptor).read().decode('utf-8')\n",
        "                    if dat[0]=='\\ufeff':  # Ignore BOM\n",
        "                        dat=dat[1:]\n",
        "                    dat=dat.replace('\\r', '')  # get rid of pesky LFs \n",
        "                    self.data += dat\n",
        "                    fd[\"title\"] = title\n",
        "                    fd[\"author\"] = author\n",
        "                    fd[\"data\"] = dat\n",
        "                    fd[\"index\"] = index\n",
        "                    index += 1\n",
        "                    valid=True\n",
        "                    self.files.append(fd)\n",
        "                except Exception as e:\n",
        "                    print(f\"Can't download {descriptor}: {e}\")\n",
        "            else:\n",
        "                fd[\"title\"] = title\n",
        "                fd[\"author\"] = author\n",
        "                try:\n",
        "                    if is_cached is True:\n",
        "                        print(f\"Reading {cache_name} from cache\")\n",
        "                        f = open(cache_name)\n",
        "                    else:    \n",
        "                        f = open(descriptor)\n",
        "                    dat = f.read(max)\n",
        "                    self.data += dat\n",
        "                    fd[\"data\"] = dat\n",
        "                    fd[\"index\"] = index\n",
        "                    index += 1\n",
        "                    self.files.append(fd)\n",
        "                    f.close()\n",
        "                    valid=True\n",
        "                except Exception as e:\n",
        "                    print(f\"ERROR: Cannot read: {filename}: {e}\")\n",
        "            if valid is True and is_cached is False and self.cache_dir is not None:\n",
        "                try:\n",
        "                    print(f\"Caching {cache_name}\")\n",
        "                    f = open(cache_name, 'w')\n",
        "                    f.write(dat)\n",
        "                    f.close()\n",
        "                except Exception as e:\n",
        "                    print(f\"ERROR: failed to save cache {cache_name}: {e}\")\n",
        "                \n",
        "                \n",
        "        ind = 0\n",
        "        for c in self.data:  # sets are not deterministic\n",
        "            if c not in self.c2i:\n",
        "                self.c2i[c] = ind\n",
        "                self.i2c[ind] = c\n",
        "                ind += 1\n",
        "        self.ptr = 0\n",
        "        \n",
        "    def display_colored_html(self, textlist, dark_mode=False, display_ref_anchor=True, pre='', post=''):\n",
        "        bgcolorsWht = ['#d4e6e1', '#d8daef', '#ebdef0', '#eadbd8', '#e2d7d5', '#edebd0',\n",
        "                    '#ecf3cf', '#d4efdf', '#d0ece7', '#d6eaf8', '#d4e6f1', '#d6dbdf',\n",
        "                    '#f6ddcc', '#fae5d3', '#fdebd0', '#e5e8e8', '#eaeded', '#A9CCE3']\n",
        "        bgcolorsDrk = ['#342621','#483a2f', '#3b4e20', '#2a3b48', '#324745', '#3d3b30',\n",
        "                    '#3c235f', '#443f4f', '#403c37', '#463a28', '#443621', '#364b5f',\n",
        "                    '#264d4c', '#2a3553', '#3d2b40', '#354838', '#3a3d4d', '#594C23']\n",
        "        if dark_mode is False:\n",
        "            bgcolors=bgcolorsWht\n",
        "        else:\n",
        "            bgcolors=bgcolorsDrk\n",
        "        out = ''\n",
        "        for txt, ind in textlist:\n",
        "            txt = txt.replace('\\n', '<br>')\n",
        "            if ind == 0:\n",
        "                out += txt\n",
        "            else:\n",
        "                if display_ref_anchor is True:\n",
        "                    anchor=\"<sup>[\" + str(ind) + \"]</sup>\"\n",
        "                else:\n",
        "                    anchor=\"\"\n",
        "                out += \"<span style=\\\"background-color:\"+bgcolors[ind % 16]+\";\\\">\" + \\\n",
        "                       txt + \"</span>\"+ anchor\n",
        "        display(HTML(pre+out+post))\n",
        "\n",
        "    def source_highlight(self, txt, minQuoteSize=10, dark_mode=False, display_ref_anchor=True):\n",
        "        tx = txt\n",
        "        out = []\n",
        "        qts = []\n",
        "        txsrc = [(\"Sources: \", 0)]\n",
        "        sc = False\n",
        "        noquote = ''\n",
        "        while len(tx) > 0:  # search all library files for quote 'txt'\n",
        "            mxQ = 0\n",
        "            mxI = 0\n",
        "            mxN = ''\n",
        "            found = False\n",
        "            for f in self.files:  # find longest quote in all texts\n",
        "                p = minQuoteSize\n",
        "                if p <= len(tx) and tx[:p] in f[\"data\"]:\n",
        "                    p = minQuoteSize + 1\n",
        "                    while p <= len(tx) and tx[:p] in f[\"data\"]:\n",
        "                        p += 1\n",
        "                    if p-1 > mxQ:\n",
        "                        mxQ = p-1\n",
        "                        mxI = f[\"index\"]\n",
        "                        mxN = f\"{f['author']}: {f['title']}\"\n",
        "                        found = True\n",
        "            if found:  # save longest quote for colorizing\n",
        "                if len(noquote) > 0:\n",
        "                    out.append((noquote, 0))\n",
        "                    noquote = ''\n",
        "                out.append((tx[:mxQ], mxI))\n",
        "                tx = tx[mxQ:]\n",
        "                if mxI not in qts:  # create a new reference, if first occurence\n",
        "                    qts.append(mxI)\n",
        "                    if sc:\n",
        "                        txsrc.append((\", \", 0))\n",
        "                    sc = True\n",
        "                    txsrc.append((mxN, mxI))\n",
        "            else:\n",
        "                noquote += tx[0]\n",
        "                tx = tx[1:]\n",
        "        if len(noquote) > 0:\n",
        "            out.append((noquote, 0))\n",
        "            noquote = ''\n",
        "        self.display_colored_html(out, dark_mode=dark_mode, display_ref_anchor=display_ref_anchor)\n",
        "        if len(qts) > 0:  # print references, if there is at least one source\n",
        "            self.display_colored_html(txsrc, dark_mode=dark_mode, display_ref_anchor=display_ref_anchor, pre=\"<small><p style=\\\"text-align:right;\\\">\",\n",
        "                                     post=\"</p></small>\")\n",
        "\n",
        "    def get_slice(self, length):\n",
        "        if (self.ptr + length >= len(self.data)):\n",
        "            self.ptr = 0\n",
        "        if self.ptr == 0:\n",
        "            rst = True\n",
        "        else:\n",
        "            rst = False\n",
        "        sl = self.data[self.ptr:self.ptr+length]\n",
        "        self.ptr += length\n",
        "        return sl, rst\n",
        "\n",
        "    def decode(self, ar):\n",
        "        return ''.join([self.i2c[ic] for ic in ar])\n",
        "\n",
        "    def get_random_slice(self, length):\n",
        "        p = random.randrange(0, len(self.data)-length)\n",
        "        sl = self.data[p:p+length]\n",
        "        return sl\n",
        "\n",
        "    def get_slice_array(self, length):\n",
        "        ar = np.array([c for c in self.get_slice(length)[0]])\n",
        "        return ar\n",
        "\n",
        "    def get_encoded_slice(self, length):\n",
        "        s, rst = self.get_slice(length)\n",
        "        X = [self.c2i[c] for c in s]\n",
        "        return X\n",
        "        \n",
        "    def get_encoded_slice_array(self, length):\n",
        "        return np.array(self.get_encoded_slice(length))\n",
        "\n",
        "    def get_sample(self, length):\n",
        "        s, rst = self.get_slice(length+1)\n",
        "        X = [self.c2i[c] for c in s[:-1]]\n",
        "        y = [self.c2i[c] for c in s[1:]]\n",
        "        return (X, y, rst)\n",
        "\n",
        "    def get_random_sample(self, length):\n",
        "        s = self.get_random_slice(length+1)\n",
        "        X = [self.c2i[c] for c in s[:-1]]\n",
        "        y = [self.c2i[c] for c in s[1:]]\n",
        "        return (X, y)\n",
        "\n",
        "    def get_sample_batch(self, batch_size, length):\n",
        "        smpX = []\n",
        "        smpy = []\n",
        "        for i in range(batch_size):\n",
        "            Xi, yi, rst = self.get_sample(length)\n",
        "            smpX.append(Xi)\n",
        "            smpy.append(yi)\n",
        "        return smpX, smpy, rst\n",
        "\n",
        "    def get_random_sample_batch(self, batch_size, length):\n",
        "        smpX = []\n",
        "        smpy = []\n",
        "        for i in range(batch_size):\n",
        "            Xi, yi = self.get_random_sample(length)\n",
        "            smpX.append(Xi)\n",
        "            smpy.append(yi)\n",
        "        return np.array(smpX), np.array(smpy)\n",
        "    \n",
        "    def get_random_onehot_sample_batch(self, batch_size, length):\n",
        "        X, y = self.get_random_sample_batch(batch_size, length)\n",
        "        return one_hot(X,len(self.i2c)), y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JcMGC5KDUloz"
      },
      "source": [
        "## 1.3 Data sources\n",
        "\n",
        "Data sources can either be:\n",
        "\n",
        "1. files from local filesystem, or for colab notebooks from google drive, \n",
        "2. http(s) links\n",
        "\n",
        "The `name` given will be use as directory name for both snapshots and model data caches.\n",
        "\n",
        "Each entry in the `lib` array contains of:\n",
        "\n",
        "1. (1) a local filename or (2) https(s) link\n",
        "2. an Author's name\n",
        "3. a title\n",
        "\n",
        "Samples: (we are using the `libdesc` created above from `GutenbergLib`\n",
        "```\n",
        "libdesc = {\n",
        "    \"name\": \"Women-Writers\",\n",
        "    \"description\": \"A collection of works of Woolf, Austen and Brontë\",\n",
        "    \"lib\": [\n",
        "        # local file:\n",
        "        # ('data/tiny-shakespeare.txt', 'William Shakespeare', 'Some parts'),\n",
        "\n",
        "        # http URLs:\n",
        "        # ('http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/100/100-0.txt', 'Shakespeare', 'Collected Works'),\n",
        "        # ('http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/3/7/4/3/37431/37431.txt', 'Jane Austen', 'Pride and Prejudice'),\n",
        "        # ('http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/7/6/768/768.txt', 'Emily Brontë', 'Wuthering Heights'),         \n",
        "        # ('http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/4/144/144.txt', 'Virginia Woolf', 'Voyage out'),\n",
        "        # ('http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/5/158/158.txt', 'Jane Austen', 'Emma'),\n",
        "    ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OTg4QFewsJdE",
        "colab": {}
      },
      "source": [
        "textlib = TextLibrary(libdesc[\"lib\"], text_data_cache_directory=data_cache_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zP0Hcs82lWYI"
      },
      "source": [
        "# 2. The deep LSTM model\n",
        "\n",
        "# 2.1 Model configuration parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EEM7Y3GxUlo0",
        "colab": {}
      },
      "source": [
        "model_params = {\n",
        "    \"model_name\": libdesc['name'],\n",
        "    \"vocab_size\": len(textlib.i2c),\n",
        "    \"neurons\": 1024,\n",
        "    \"layers\": 6,\n",
        "    \"learning_rate\": 1.e-3,\n",
        "    \"steps\": 60,\n",
        "    \"batch_size\": 512\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m_JWmbgPUlpG"
      },
      "source": [
        "## 2.2 The char-rnn model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NcsP8OYlUlpH",
        "colab": {}
      },
      "source": [
        "class Poet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, device):\n",
        "        super(Poet, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.output_size = output_size\n",
        "        self.device=device\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=0)\n",
        "        \n",
        "        self.demb = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=-1)  # negative dims are a recent thing (as 2018-03), remove for old vers.\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        self.h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n",
        "        self.c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)\n",
        "\n",
        "    def forward(self, inputx, steps):\n",
        "        self.lstm.flatten_parameters()\n",
        "        hn, (self.h0, self.c0) = self.lstm(inputx.to(self.device), (self.h0, self.c0))\n",
        "        hnr = hn.contiguous().view(-1,self.hidden_size)\n",
        "        op = self.demb(hnr)\n",
        "        opr = op.view(-1, steps ,self.output_size)\n",
        "        return opr\n",
        "\n",
        "    def generate(self, n, start=None, temperature=1.0):\n",
        "        s=''\n",
        "        torch.set_grad_enabled(False)\n",
        "        if start==None or len(start)==0:\n",
        "            start=' '\n",
        "        self.init_hidden(1)\n",
        "        for c in start:\n",
        "            X=np.array([[textlib.c2i[c]]])\n",
        "            Xo=one_hot(X,self.output_size)\n",
        "            Xt = Tensor(torch.from_numpy(np.array(Xo,dtype=np.float32))).to(self.device)\n",
        "            ypl = self.forward(Xt,1)\n",
        "            ypl2 = ypl.view(-1,self.output_size)\n",
        "            if temperature>0.0:\n",
        "                ypl2 = ypl2 / temperature\n",
        "            yp = self.softmax(ypl2)\n",
        "        for i in range(n):\n",
        "            ypc=Tensor.cpu(yp.detach()) # .cpu()\n",
        "            y_pred=ypc.numpy()\n",
        "            inds=list(range(self.output_size))\n",
        "            ind = np.random.choice(inds, p=y_pred.ravel())\n",
        "            s=s+textlib.i2c[ind]\n",
        "            X=np.array([[ind]])\n",
        "            Xo=one_hot(X,self.output_size)\n",
        "            Xt = Tensor(torch.from_numpy(np.array(Xo,dtype=np.float32))).to(self.device)\n",
        "            ypl = self.forward(Xt,1)\n",
        "            ypl2 = ypl.view(-1,self.output_size)\n",
        "            if temperature>0.0:\n",
        "                ypl2 = ypl2 / temperature\n",
        "            yp = self.softmax(ypl2)\n",
        "        torch.set_grad_enabled(True)\n",
        "        return s    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ymdU_wIWUlpK"
      },
      "source": [
        "## 2.3 Model instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L7WuQ142UlpL",
        "colab": {}
      },
      "source": [
        "poet = Poet(model_params['vocab_size'], model_params['neurons'], model_params['layers'], model_params['vocab_size'], device).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FJp6Sjw6UlpP"
      },
      "source": [
        "## 2.4 Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aeFxMxyuUlpQ",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = model_params['learning_rate']\n",
        "\n",
        "opti = torch.optim.Adam(poet.parameters(),lr=learning_rate);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XtKdvxNymXpM"
      },
      "source": [
        "## 2.5 Helper Functions\n",
        "\n",
        "These allow to save or restore the training data. Saving and restoring can either be performed:\n",
        "\n",
        "* Jupyter: store/restore in a local directory,\n",
        "* Colab: store/restore on google drive. The training-code (using load_checkpoint()) will display an authentication url and code input-box in order to be able to access your google drive from this notebook. This allows to continue training sessions (or inference) after the Colab session was terminated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BfmdQ6zCMy2L",
        "colab": {}
      },
      "source": [
        "if is_colab_notebook:\n",
        "    if colab_google_drive_snapshots is True:\n",
        "        snapshot_path=os.path.join(root_path,f\"Colab Notebooks/{model_params['model_name']}/Snapshots\")\n",
        "    else:\n",
        "        snapshot_path=None\n",
        "else:\n",
        "    snapshot_path=os.path.join(root_path,f\"{model_params['model_name']}/Snapshots\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AuVlJksgsJde",
        "colab": {}
      },
      "source": [
        "def get_project_path():\n",
        "    if snapshot_path is None:\n",
        "        return None\n",
        "    project_path_ext=f\"model-{model_params['vocab_size']}x{model_params['steps']}x{model_params['layers']}x{model_params['neurons']}\"\n",
        "    return os.path.join(snapshot_path, project_path_ext)\n",
        "\n",
        "def create_project_path():\n",
        "    if snapshot_path is None:\n",
        "        return None\n",
        "    ppath=get_project_path()\n",
        "    pathlib.Path(ppath).mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QebezmDgsJdh",
        "colab": {}
      },
      "source": [
        "if snapshot_path is not None:\n",
        "    pathlib.Path(snapshot_path).mkdir(parents=True, exist_ok=True)\n",
        "    create_project_path()\n",
        "    with open(os.path.join(get_project_path(),'model_params.json'),'w') as f:\n",
        "        json.dump(model_params,f,indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T3v82UHQsJdj",
        "colab": {}
      },
      "source": [
        "best_pr=0.0\n",
        "\n",
        "def save_checkpoint(epoch, loss, pr, filename='checkpoint.pth.tar'):\n",
        "    if snapshot_path is None:\n",
        "        return\n",
        "    global best_pr\n",
        "    state={\n",
        "            'epoch': epoch,\n",
        "            'model_config': model_params,\n",
        "            'state_dict': poet.state_dict(),\n",
        "            'optimizer' : opti.state_dict(),\n",
        "            'precision': pr,\n",
        "            'loss': loss,\n",
        "        }\n",
        "    project_path=get_project_path()\n",
        "    save_file=os.path.join(project_path,filename)\n",
        "    best_file=os.path.join(project_path,'model_best.pth.tar')\n",
        "    torch.save(state, save_file)\n",
        "    if pr>best_pr:\n",
        "        best_pr=pr\n",
        "        shutil.copyfile(save_file, best_file )\n",
        "        print(f\"Saved best precision model, prec={pr}\")\n",
        "    else:\n",
        "        print(f\"saved last model data, prec={pr}\")\n",
        "\n",
        "def save_history(history, filename=\"history.json\"):\n",
        "    if snapshot_path is None:\n",
        "        return\n",
        "    project_path=get_project_path()\n",
        "    save_file=os.path.join(project_path,filename)\n",
        "    try:\n",
        "        with open(save_file, 'w') as f:\n",
        "            json.dump(history, f)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to write training history file {save_file}, {e}\")\n",
        "\n",
        "def load_checkpoint(filename='checkpoint.pth.tar'):\n",
        "    if snapshot_path is None:\n",
        "        return 0,0\n",
        "    project_path=get_project_path()\n",
        "    load_file=os.path.join(project_path,filename)\n",
        "    if not os.path.exists(load_file):\n",
        "        print(load_file)\n",
        "        print(\"No saved state, starting from scratch.\")\n",
        "        return 0,0\n",
        "    state=torch.load(load_file)\n",
        "    mod_conf = state['model_config']\n",
        "    if (mod_conf['model_name']!=model_params['model_name']):\n",
        "        print(f\"Warning: project has been renamed from {mod_conf['model_name']} to {model_param['model_name']}\")\n",
        "        mod_conf['model_name']=model_params['model_name']\n",
        "    if model_params!=mod_conf:\n",
        "        print(f\"The saved model has a different configuration than the current model: {mod_conf} vs. {model_params}\")\n",
        "        print(\"Cannot restore state, starting from scratch.\")\n",
        "        return 0,0\n",
        "    poet.load_state_dict(state['state_dict'])\n",
        "    opti.load_state_dict(state['optimizer'])\n",
        "    epoch = state['epoch']\n",
        "    loss = state['loss']\n",
        "    best_pr = state['precision']\n",
        "    print(f\"Continuing from saved state epoch={epoch}, loss={loss}\")  # Save is not necessarily on epoch boundary, so that's approx.\n",
        "    return epoch,loss\n",
        "\n",
        "# def one_hot(p, dim):\n",
        "#     o=np.zeros(p.shape+(dim,), dtype=int32)\n",
        "#     for y in range(p.shape[0]):\n",
        "#         for x in range(p.shape[1]):\n",
        "#             o[y,x,p[y,x]]=1\n",
        "#     return o"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a_-ISha4nqhy"
      },
      "source": [
        "# 3. Training\n",
        "\n",
        "If there is already saved training data, this step is optional, and alternatively, ch. 4 can be continued."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9KDRpEm0n7B-"
      },
      "source": [
        "## 3.1 Training helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_pZlsZ1Pnm5Z",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "    Xo, y=textlib.get_random_onehot_sample_batch(model_params['batch_size'], model_params['steps'])\n",
        "    # Xo = one_hot(X, model_params['vocab_size'])\n",
        "    \n",
        "    # Xt = Tensor(torch.from_numpy(np.array(Xo,dtype=np.float32)), requires_grad=False, dtype=torch.float32, device=device)\n",
        "    # yt = Tensor(torch.from_numpy(y), requires_grad=False, dtype=torch.int32, device=device)\n",
        "    Xt = Tensor(torch.from_numpy(np.array(Xo,dtype=np.float32))).to(device)\n",
        "    Xt.requires_grad_(False)\n",
        "    yt = torch.LongTensor(torch.from_numpy(np.array(y,dtype=np.int64))).to(device)\n",
        "    yt.requires_grad_(False)\n",
        "    return Xt, yt\n",
        "\n",
        "def train(Xt, yt, bPr=False):\n",
        "    poet.zero_grad()\n",
        "\n",
        "    poet.init_hidden(Xt.size(0))\n",
        "    output = poet(Xt, model_params['steps'])\n",
        "    \n",
        "    olin=output.view(-1,model_params['vocab_size'])\n",
        "    _, ytp=torch.max(olin,1)\n",
        "    ytlin=yt.view(-1)\n",
        "\n",
        "    pr=0.0\n",
        "    if bPr: # Calculate precision\n",
        "        ok=0\n",
        "        nok=0\n",
        "        for i in range(ytlin.size()[0]):\n",
        "            i1=ytlin[i].item()\n",
        "            i2=ytp[i].item()\n",
        "            if i1==i2:\n",
        "                ok = ok + 1\n",
        "            else:\n",
        "                nok = nok+1\n",
        "            pr=ok/(ok+nok)\n",
        "            \n",
        "    loss = criterion(olin, ytlin)\n",
        "    ls = loss.item()\n",
        "    loss.backward()\n",
        "    opti.step()\n",
        "\n",
        "    return ls, pr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KC36hNRKUlpU"
      },
      "source": [
        "## 3.2 The actual training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q9-3GUQ4UlpV",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c92282d1-caa4-4641-ebbe-f630e4aef30f"
      },
      "source": [
        "ls=0\n",
        "nrls=0\n",
        "\n",
        "create_project_path()\n",
        "epoch_start, _ = load_checkpoint()\n",
        "\n",
        "history=[]\n",
        "\n",
        "# Make a snapshot of the trained parameters every snapshot_interval_sec\n",
        "snapshot_interval_sec=300\n",
        "# Generate text samples every sample_intervall_sec\n",
        "sample_interval_sec=600\n",
        "\n",
        "start_time=time.time()\n",
        "last_snapshot=time.time()\n",
        "last_sample=time.time()\n",
        "for e in range(epoch_start,2500000):\n",
        "    Xt, yt = get_data()\n",
        "    if (e+1)%intv==0:\n",
        "        l,pr=train(Xt,yt,True)\n",
        "    else:\n",
        "        l,pr=train(Xt,yt,False)        \n",
        "    ls=ls+l\n",
        "    nrls=nrls+1\n",
        "    cur_loss=ls/nrls\n",
        "    if time.time()-last_snapshot > snapshot_interval_sec:\n",
        "        nrls=0\n",
        "        ls=0\n",
        "        last_snapshot=time.time()\n",
        "        print(f\"Epoch {e+1} Loss: {cur_loss} Precision: {pr}\")\n",
        "        save_checkpoint(e,cur_loss,pr)\n",
        "        # if use_cuda:\n",
        "        #     print(f\"Cuda memory allocated: {torch.cuda.memory_allocated()} max_alloc: {torch.cuda.max_memory_allocated()} cached: {torch.cuda.memory_cached()} max_cached: {torch.cuda.max_memory_cached()}\")\n",
        "        hist={\"epoch\": e, \"loss\": cur_loss, \"precision\": pr, \"timestamp\": time.time()-start_time}\n",
        "        history.append(hist)\n",
        "        save_history(history)\n",
        "    if time.time()-last_sample > sample_intervall_sec:\n",
        "        last_sample=time.time()\n",
        "        for temperature in [0.6, 0.8, 1.0]:\n",
        "            print(f\"Temperature {temperature}:\")\n",
        "            tgen=poet.generate(700,\". \", temperature=temperature)\n",
        "            textlib.source_highlight(tgen,minQuoteSize=10,dark_mode=use_dark_mode,display_ref_anchor=False)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Continuing from saved state epoch=18499, loss=1.210113525390625\n",
            "Epoch 18500 Loss: 1.2006293535232544 Precision: 0.6310546875\n",
            "Saved best precision model, prec=0.6310546875\n",
            "Temperature 0.6:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "133<span style=\"background-color:#d0ece7;\">. The present ex</span><span style=\"background-color:#eadbd8;\">istence of the s</span><span style=\"background-color:#e2d7d5;\">tudy of the m</span><span style=\"background-color:#edebd0;\">anner of the p</span>art,<span style=\"background-color:#ecf3cf;\"> all<br>substan</span><span style=\"background-color:#edebd0;\">tive realization </span><span style=\"background-color:#d6dbdf;\">of the latter that i</span><span style=\"background-color:#d4efdf;\">s the beautiful </span><span style=\"background-color:#d6dbdf;\">with the possibility of </span><span style=\"background-color:#d4e6f1;\">our sense of the </span><span style=\"background-color:#e2d7d5;\">special consideration of the</span><span style=\"background-color:#d6dbdf;\"> present subject, th</span><span style=\"background-color:#d8daef;\">is is the most p</span>rod<span style=\"background-color:#e5e8e8;\">uctibility of</span><span style=\"background-color:#fae5d3;\"><br>the will to </span><span style=\"background-color:#eadbd8;\">the interest. </span><span style=\"background-color:#d4efdf;\">We shall therefore </span>se<span style=\"background-color:#d4e6e1;\">e it to see</span><span style=\"background-color:#e2d7d5;\"> that the ordinary man</span><span style=\"background-color:#d0ece7;\"> that content b</span><span style=\"background-color:#f6ddcc;\">elongs to the di</span><span style=\"background-color:#e2d7d5;\">rection of an </span><span style=\"background-color:#e2d7d5;\">antagonistic </span>wa<span style=\"background-color:#d6eaf8;\">y as every </span><span style=\"background-color:#d0ece7;\">action which is fo</span>rm<span style=\"background-color:#d8daef;\">ally from m</span>or<span style=\"background-color:#d6dbdf;\">e<br>supreme power, </span><span style=\"background-color:#d4efdf;\">the plant </span><span style=\"background-color:#d6eaf8;\">depend upon them</span><span style=\"background-color:#edebd0;\">, in our modern</span><span style=\"background-color:#d0ece7;\"><br>vision and </span><span style=\"background-color:#d4efdf;\">the interest in the </span><span style=\"background-color:#ecf3cf;\">first principles, </span><span style=\"background-color:#eadbd8;\">so that of a </span><span style=\"background-color:#eadbd8;\">perfect app</span><span style=\"background-color:#eadbd8;\">earance of the s</span><span style=\"background-color:#d8daef;\">ubject in which the </span><span style=\"background-color:#e2d7d5;\">development of the same</span><span style=\"background-color:#d8daef;\"> sense be a</span>llo<span style=\"background-color:#edebd0;\">wed as an </span><span style=\"background-color:#d0ece7;\">external one, </span><span style=\"background-color:#edebd0;\">but as a pr</span><span style=\"background-color:#fdebd0;\">inciple of their action</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d0ece7;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 1 of 4</span>, <span style=\"background-color:#eadbd8;\">David Hume: Hume's Political Discourses</span>, <span style=\"background-color:#e2d7d5;\">Friedrich Nietzsche: Thoughts Out of Season, Part 2</span>, <span style=\"background-color:#edebd0;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span>, <span style=\"background-color:#edebd0;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 4 of 4</span>, <span style=\"background-color:#d6dbdf;\">Immanuel Kant: Kant's Critique of Judgement</span>, <span style=\"background-color:#d4efdf;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 2 of 4</span>, <span style=\"background-color:#d4e6f1;\">William Wallace and G. W. F. Hegel: Prolegomena to the Study of Hegel's Philosophy</span>, <span style=\"background-color:#e2d7d5;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#d6dbdf;\">David Hume: Philosophical Works, Vol. 2 of 4</span>, <span style=\"background-color:#d8daef;\">Friedrich Wilhelm Nietzsche: The Dawn of Day</span>, <span style=\"background-color:#e5e8e8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 3 of 3)</span>, <span style=\"background-color:#fae5d3;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#d4efdf;\">Friedrich Wilhelm Nietzsche: On the Future of our Educational Institutions - Homer and Classical Philology</span>, <span style=\"background-color:#d4e6e1;\">Montaigne, Michel, Sainte-Beuve, Charles-Augustin; Renan, Ernest, Lessing, Gotthold Ephraim, Von Schiller, J.C., Kant, Immanuel, Mazzini, and Giuseppe: Literary and Philosophical Essays</span>, <span style=\"background-color:#e2d7d5;\">Friedrich Nietzsche: Beyond Good and Evil</span>, <span style=\"background-color:#f6ddcc;\">Georg Hegel: The Introduction to Hegel's Philosophy of Fine Arts</span>, <span style=\"background-color:#e2d7d5;\">Friedrich Wilhelm Nietzsche: Thoughts out of Season, Part I</span>, <span style=\"background-color:#d6eaf8;\">Arthur Schopenhauer: On the Fourfold Root of the Principle of Sufficient Reason and On the Will in Nature: Two Essays (revised edition)</span>, <span style=\"background-color:#d8daef;\">Søren Kierkegaard: Selections from the Writings of Kierkegaard</span>, <span style=\"background-color:#d6dbdf;\">John Locke: Second Treatise of Government</span>, <span style=\"background-color:#d6eaf8;\">G. W. Leibniz: Theodicy</span>, <span style=\"background-color:#ecf3cf;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 3 of 4</span>, <span style=\"background-color:#eadbd8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#eadbd8;\">Rene Descartes: Selections From The Principles of Philosophy</span>, <span style=\"background-color:#d8daef;\">David Hume: A Treatise of Human Nature, Vols. 1 & 2</span>, <span style=\"background-color:#fdebd0;\">Immanuel Kant: The Critique of Practical Reason</span></p></small>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Temperature 0.8:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Art,<span style=\"background-color:#d6eaf8;\"> Ethics are </span><span style=\"background-color:#d8daef;\">to be capable of action</span><span style=\"background-color:#e2d7d5;\">, either un</span>to<span style=\"background-color:#ecf3cf;\"><br>the metaphysic of </span><span style=\"background-color:#eadbd8;\">the succession of the </span><span style=\"background-color:#eadbd8;\">person and the </span><span style=\"background-color:#eadbd8;\">most relati</span><span style=\"background-color:#ecf3cf;\">ve form of p</span><span style=\"background-color:#e2d7d5;\">hilosophy, it is a</span>s s<span style=\"background-color:#ecf3cf;\">o better, the</span><span style=\"background-color:#d4e6e1;\">refore, the ma</span><span style=\"background-color:#edebd0;\">in purpose, </span><span style=\"background-color:#edebd0;\">the limited e</span>mpty <span style=\"background-color:#f6ddcc;\">sand, and on the </span><span style=\"background-color:#e5e8e8;\">contrary<br>to a</span><span style=\"background-color:#d6dbdf;\">ttend to the </span><span style=\"background-color:#d6eaf8;\">will to the c</span><span style=\"background-color:#d6dbdf;\">orrespondence to</span><span style=\"background-color:#edebd0;\"> the one to the </span><span style=\"background-color:#d0ece7;\">sense in its</span><span style=\"background-color:#edebd0;\"> result of the whole </span><span style=\"background-color:#d4e6e1;\">manner in o</span><span style=\"background-color:#d4efdf;\">rder to be really </span>the power<span style=\"background-color:#d4e6f1;\">: sometimes </span><span style=\"background-color:#ecf3cf;\">on the other hand, the ne</span><span style=\"background-color:#edebd0;\">cessary contra</span>ry<span style=\"background-color:#edebd0;\"> hand, which </span><span style=\"background-color:#d4e6e1;\">more explain</span><span style=\"background-color:#ecf3cf;\">ed from the same </span><span style=\"background-color:#edebd0;\">assumptions, and the</span><span style=\"background-color:#e2d7d5;\">refore not th</span><span style=\"background-color:#d4e6f1;\">at they were o</span><span style=\"background-color:#d6dbdf;\">ften observed</span><span style=\"background-color:#d4e6e1;\">; there they w</span><span style=\"background-color:#d6eaf8;\">ere a body</span><span style=\"background-color:#e5e8e8;\">, also, as </span><span style=\"background-color:#d4e6e1;\">well as a p</span><span style=\"background-color:#d4e6f1;\">osition. It is </span><span style=\"background-color:#edebd0;\">only the subjectiv</span><span style=\"background-color:#edebd0;\">ity of objectivity</span><span style=\"background-color:#d6eaf8;\"> to what we ca</span><span style=\"background-color:#d8daef;\">n direct t</span>he<br>auth<span style=\"background-color:#d8daef;\">ry of detail</span><span style=\"background-color:#e5e8e8;\"> of a possible c</span><span style=\"background-color:#fae5d3;\">oncept of the p</span>henome"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d6eaf8;\">Arthur Schopenhauer: On the Fourfold Root of the Principle of Sufficient Reason and On the Will in Nature: Two Essays (revised edition)</span>, <span style=\"background-color:#d8daef;\">Friedrich Wilhelm Nietzsche: The Genealogy of Morals</span>, <span style=\"background-color:#e2d7d5;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span>, <span style=\"background-color:#eadbd8;\">David Hume: Hume's Political Discourses</span>, <span style=\"background-color:#eadbd8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#ecf3cf;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 1 of 3</span>, <span style=\"background-color:#d4e6e1;\">Montaigne, Michel, Sainte-Beuve, Charles-Augustin; Renan, Ernest, Lessing, Gotthold Ephraim, Von Schiller, J.C., Kant, Immanuel, Mazzini, and Giuseppe: Literary and Philosophical Essays</span>, <span style=\"background-color:#edebd0;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 4 of 4</span>, <span style=\"background-color:#edebd0;\">David Hume: An Enquiry Concerning the Principles of Morals</span>, <span style=\"background-color:#f6ddcc;\">David Hume: Philosophical Works, Vol. 1 of 4</span>, <span style=\"background-color:#e5e8e8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 3 of 3)</span>, <span style=\"background-color:#d6dbdf;\">David Hume: Philosophical Works, Vol. 2 of 4</span>, <span style=\"background-color:#d6eaf8;\">G. W. Leibniz: Theodicy</span>, <span style=\"background-color:#d0ece7;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 1 of 4</span>, <span style=\"background-color:#edebd0;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span>, <span style=\"background-color:#d4e6e1;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 2 of 3)</span>, <span style=\"background-color:#d4efdf;\">Friedrich Nietzsche: Thus Spake Zarathustra</span>, <span style=\"background-color:#d4e6f1;\">William Wallace and G. W. F. Hegel: Prolegomena to the Study of Hegel's Philosophy</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Wilhelm Nietzsche: Human, All-Too-Human, Part II</span>, <span style=\"background-color:#ecf3cf;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 3 of 4</span>, <span style=\"background-color:#d6eaf8;\">G. W. F. Hegel: The Logic of Hegel</span>, <span style=\"background-color:#d4e6e1;\">Immanuel Kant: Kant's Prolegomena</span>, <span style=\"background-color:#d8daef;\">Søren Kierkegaard: Selections from the Writings of Kierkegaard</span>, <span style=\"background-color:#e5e8e8;\">Immanuel Kant: Fundamental Principles of the Metaphysic of Morals</span>, <span style=\"background-color:#fae5d3;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span></p></small>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Temperature 1.0:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"background-color:#e5e8e8;\">No longer </span>mak<span style=\"background-color:#eadbd8;\">es in all natur</span><span style=\"background-color:#eadbd8;\">e is only<br>p</span><span style=\"background-color:#d4e6f1;\">erceived at </span><span style=\"background-color:#edebd0;\">all, in the </span>ou<span style=\"background-color:#d4e6f1;\">t of in the </span>writers O<span style=\"background-color:#e2d7d5;\"> theology. A</span> valid mind b<span style=\"background-color:#eadbd8;\">y business in </span>the p<span style=\"background-color:#e5e8e8;\">aching has </span><span style=\"background-color:#fdebd0;\">been only a </span>f<span style=\"background-color:#d6eaf8;\">ree degree</span><span style=\"background-color:#e5e8e8;\">.<br>Consequently a</span><span style=\"background-color:#e2d7d5;\">n actual se</span>nt<span style=\"background-color:#eadbd8;\">ence it th</span><span style=\"background-color:#fae5d3;\">us endeavours</span><span style=\"background-color:#e2d7d5;\">, and by which </span><span style=\"background-color:#edebd0;\">our pretensions </span><span style=\"background-color:#d8daef;\">did not de</span>m<span style=\"background-color:#edebd0;\">and to develop the </span><span style=\"background-color:#fdebd0;\">virtue, let </span><span style=\"background-color:#d6dbdf;\">us a subject, and </span><span style=\"background-color:#eadbd8;\">citizen wh</span><span style=\"background-color:#e5e8e8;\">en only a f</span>ew<span style=\"background-color:#d8daef;\">er doubt w</span><span style=\"background-color:#e2d7d5;\">e associate the</span><span style=\"background-color:#f6ddcc;\"><br>particular object</span><span style=\"background-color:#d4efdf;\"> and object the</span><span style=\"background-color:#e5e8e8;\"> methods of ma</span><span style=\"background-color:#ebdef0;\">n, then the </span><span style=\"background-color:#eadbd8;\">same way su</span><span style=\"background-color:#ecf3cf;\">itably from th</span><span style=\"background-color:#ecf3cf;\">e experience of these</span>,<span style=\"background-color:#d6eaf8;\"> the Identity</span><span style=\"background-color:#d4e6f1;\"> of knowledge is not </span><span style=\"background-color:#edebd0;\">only formal, </span><span style=\"background-color:#edebd0;\">that is, the immedia</span>c<span style=\"background-color:#edebd0;\">y<br>was the </span><span style=\"background-color:#e2d7d5;\">cause of the wor</span>md<span style=\"background-color:#d0ece7;\"> of art<br>wh</span><span style=\"background-color:#e5e8e8;\">ether in their pr</span>om<span style=\"background-color:#fae5d3;\">ise as a rea</span>l<span style=\"background-color:#eadbd8;\"> and neither </span><span style=\"background-color:#d6dbdf;\">religion, re</span><span style=\"background-color:#edebd0;\">lated that which i</span><span style=\"background-color:#edebd0;\">n points of </span><span style=\"background-color:#d8daef;\">one please</span>:<span style=\"background-color:#d6eaf8;\"> what Kant<br></span>adds the sud<span style=\"background-color:#d4e6e1;\">cended of </span>me"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#e5e8e8;\">Friedrich Nietzsche: The Joyful Wisdom</span>, <span style=\"background-color:#eadbd8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#d4e6f1;\">William Wallace and G. W. F. Hegel: Prolegomena to the Study of Hegel's Philosophy</span>, <span style=\"background-color:#edebd0;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 4 of 4</span>, <span style=\"background-color:#e2d7d5;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#eadbd8;\">David Hume: Hume's Political Discourses</span>, <span style=\"background-color:#e5e8e8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 3 of 3)</span>, <span style=\"background-color:#fdebd0;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#d6eaf8;\">Arthur Schopenhauer: On the Fourfold Root of the Principle of Sufficient Reason and On the Will in Nature: Two Essays (revised edition)</span>, <span style=\"background-color:#fae5d3;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#edebd0;\">David Hume: An Enquiry Concerning the Principles of Morals</span>, <span style=\"background-color:#d8daef;\">Søren Kierkegaard: Selections from the Writings of Kierkegaard</span>, <span style=\"background-color:#edebd0;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span>, <span style=\"background-color:#fdebd0;\">Arthur Schopenhauer: The Basis of Morality</span>, <span style=\"background-color:#d6dbdf;\">David Hume: Philosophical Works, Vol. 2 of 4</span>, <span style=\"background-color:#f6ddcc;\">David Hume: Philosophical Works, Vol. 1 of 4</span>, <span style=\"background-color:#d4efdf;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 2 of 4</span>, <span style=\"background-color:#ebdef0;\">Friedrich Wilhelm Nietzsche: Twilight of the Idols - The Antichrist</span>, <span style=\"background-color:#eadbd8;\">Rene Descartes: Selections From The Principles of Philosophy</span>, <span style=\"background-color:#ecf3cf;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 1 of 3</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span>, <span style=\"background-color:#d6eaf8;\">G. W. F. Hegel: The Logic of Hegel</span>, <span style=\"background-color:#d0ece7;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 1 of 4</span>, <span style=\"background-color:#d4e6e1;\">Montaigne, Michel, Sainte-Beuve, Charles-Augustin; Renan, Ernest, Lessing, Gotthold Ephraim, Von Schiller, J.C., Kant, Immanuel, Mazzini, and Giuseppe: Literary and Philosophical Essays</span></p></small>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19000 Loss: 1.2106629526615142 Precision: 0.6271484375\n",
            "saved last model data, prec=0.6271484375\n",
            "Temperature 0.6:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"background-color:#d6eaf8;\">But this is th</span><span style=\"background-color:#d4efdf;\">is sphere of the </span><span style=\"background-color:#edebd0;\">faculty of ob</span><span style=\"background-color:#e5e8e8;\">jective<br>knowledge</span><span style=\"background-color:#fae5d3;\"> has seen th</span><span style=\"background-color:#fdebd0;\">rough them. The </span><span style=\"background-color:#ebdef0;\">general substance</span><span style=\"background-color:#e2d7d5;\">s are not merely </span><span style=\"background-color:#eadbd8;\">a superior t</span><span style=\"background-color:#edebd0;\">ransformation, </span><span style=\"background-color:#e2d7d5;\">or the absolute </span><span style=\"background-color:#fdebd0;\">consequences of the </span><span style=\"background-color:#e2d7d5;\">beautiful and the </span><span style=\"background-color:#d6eaf8;\">objects of the<br></span><span style=\"background-color:#e5e8e8;\">mind, which can </span><span style=\"background-color:#ebdef0;\">be a form of </span><span style=\"background-color:#ecf3cf;\">externality, which </span><span style=\"background-color:#d6dbdf;\">contains their </span><span style=\"background-color:#e2d7d5;\">process, and to </span><span style=\"background-color:#d0ece7;\">be presented to the </span><span style=\"background-color:#d8daef;\">apparent poss</span><span style=\"background-color:#d6dbdf;\">ibility of the highest</span><span style=\"background-color:#d4efdf;\"> and individual s</span><span style=\"background-color:#f6ddcc;\">enses and p</span><span style=\"background-color:#ecf3cf;\">roperty of the sens</span><span style=\"background-color:#e2d7d5;\">e of substance, </span><span style=\"background-color:#d4efdf;\">still<br>remains e</span><span style=\"background-color:#edebd0;\">xternal expression</span><span style=\"background-color:#eadbd8;\">s, but in the s</span><span style=\"background-color:#d4e6f1;\">ame particular a</span><span style=\"background-color:#d4e6f1;\">nd effect with the</span><span style=\"background-color:#e2d7d5;\"> language of su</span><span style=\"background-color:#e2d7d5;\">bjective cont</span><span style=\"background-color:#d0ece7;\">radiction the</span><span style=\"background-color:#ecf3cf;\">y are exte</span>r<span style=\"background-color:#e5e8e8;\">nally that of </span><span style=\"background-color:#ecf3cf;\">particular theory </span><span style=\"background-color:#edebd0;\">in the limits of<br></span><span style=\"background-color:#eadbd8;\">reason which has been </span><span style=\"background-color:#e2d7d5;\">actuality for </span><span style=\"background-color:#d6dbdf;\">its preceding </span><span style=\"background-color:#d4e6e1;\">and possible ex</span><span style=\"background-color:#d8daef;\">istence, while </span><span style=\"background-color:#e2d7d5;\">in the fact that i</span>s t"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d6eaf8;\">G. W. F. Hegel: The Logic of Hegel</span>, <span style=\"background-color:#d4efdf;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 2 of 4</span>, <span style=\"background-color:#edebd0;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span>, <span style=\"background-color:#e5e8e8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 3 of 3)</span>, <span style=\"background-color:#fae5d3;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#fdebd0;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Friedrich Hegel: Hegel's Philosophy of Mind</span>, <span style=\"background-color:#e2d7d5;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#eadbd8;\">David Hume: Hume's Political Discourses</span>, <span style=\"background-color:#edebd0;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 4 of 4</span>, <span style=\"background-color:#ebdef0;\">Friedrich Wilhelm Nietzsche: Twilight of the Idols - The Antichrist</span>, <span style=\"background-color:#ecf3cf;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 3 of 4</span>, <span style=\"background-color:#d6dbdf;\">Immanuel Kant: Kant's Critique of Judgement</span>, <span style=\"background-color:#e2d7d5;\">Friedrich Nietzsche: Thoughts Out of Season, Part 2</span>, <span style=\"background-color:#d0ece7;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 1 of 4</span>, <span style=\"background-color:#d8daef;\">Søren Kierkegaard: Selections from the Writings of Kierkegaard</span>, <span style=\"background-color:#f6ddcc;\">David Hume: Philosophical Works, Vol. 1 of 4</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span>, <span style=\"background-color:#eadbd8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#d4e6f1;\">William Wallace and G. W. F. Hegel: Prolegomena to the Study of Hegel's Philosophy</span>, <span style=\"background-color:#e2d7d5;\">Friedrich Nietzsche: Beyond Good and Evil</span>, <span style=\"background-color:#e5e8e8;\">Immanuel Kant: Fundamental Principles of the Metaphysic of Morals</span>, <span style=\"background-color:#d6dbdf;\">David Hume: Philosophical Works, Vol. 2 of 4</span>, <span style=\"background-color:#d4e6e1;\">Immanuel Kant: Kant's Prolegomena</span>, <span style=\"background-color:#d8daef;\">Friedrich Wilhelm Nietzsche: The Genealogy of Morals</span></p></small>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Temperature 0.8:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "A<span style=\"background-color:#d4e6e1;\">. The course of </span><span style=\"background-color:#eadbd8;\">what he<br>was </span><span style=\"background-color:#d0ece7;\">in other words, by the </span><span style=\"background-color:#d0ece7;\">garden of </span><span style=\"background-color:#ecf3cf;\">which we shall s</span><span style=\"background-color:#edebd0;\">hould rather h</span>ea<span style=\"background-color:#edebd0;\">t and without </span><span style=\"background-color:#d8daef;\">living in </span><span style=\"background-color:#edebd0;\">fact, but </span>not bestimmi<span style=\"background-color:#fae5d3;\">tely becomes </span><span style=\"background-color:#d4e6f1;\">the opposite one</span>. A<span style=\"background-color:#d6eaf8;\"> creation there</span>for<span style=\"background-color:#ebdef0;\">e is defined b</span><span style=\"background-color:#d4e6e1;\">y the form of m</span>en, bla<span style=\"background-color:#d6dbdf;\">me<br>the con</span><span style=\"background-color:#d6dbdf;\">struction of their </span><span style=\"background-color:#fdebd0;\">explanation of e</span>ac<span style=\"background-color:#e2d7d5;\">h and absolute</span><span style=\"background-color:#d4e6e1;\"> experience.<br>Consequently th</span><span style=\"background-color:#e2d7d5;\">is alone s</span>pea<span style=\"background-color:#eadbd8;\">k of physic</span><span style=\"background-color:#d6dbdf;\">al advantages and </span><span style=\"background-color:#d6eaf8;\">souls, that </span><span style=\"background-color:#e2d7d5;\">the reality or </span><span style=\"background-color:#ecf3cf;\">external existence w</span>as les<span style=\"background-color:#e5e8e8;\">s beginning w</span><span style=\"background-color:#d4e6e1;\">here they ne</span><span style=\"background-color:#fdebd0;\">ver exist, </span><span style=\"background-color:#ecf3cf;\">because in its present</span><span style=\"background-color:#ecf3cf;\">ation more im</span><span style=\"background-color:#f6ddcc;\">possible to prevent the</span><span style=\"background-color:#eadbd8;\">mselves to the </span><span style=\"background-color:#d6dbdf;\">will to be </span><span style=\"background-color:#edebd0;\">found as the </span><span style=\"background-color:#ecf3cf;\">only opposite</span> world.[251]<span style=\"background-color:#d6dbdf;\"><br><br>If the given </span><span style=\"background-color:#d0ece7;\">constant rea</span>son;<span style=\"background-color:#d6dbdf;\"> as purposive </span><span style=\"background-color:#ebdef0;\">principle and in</span><span style=\"background-color:#e2d7d5;\">ternal and s</span>ati<span style=\"background-color:#e2d7d5;\">re represented a</span><span style=\"background-color:#d0ece7;\">t these ni</span><span style=\"background-color:#e2d7d5;\">ghts and principles</span><span style=\"background-color:#edebd0;\"> of all art</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d4e6e1;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 2 of 3)</span>, <span style=\"background-color:#eadbd8;\">David Hume: Hume's Political Discourses</span>, <span style=\"background-color:#d0ece7;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 1 of 4</span>, <span style=\"background-color:#ecf3cf;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 1 of 3</span>, <span style=\"background-color:#edebd0;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 4 of 4</span>, <span style=\"background-color:#d8daef;\">Søren Kierkegaard: Selections from the Writings of Kierkegaard</span>, <span style=\"background-color:#fae5d3;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#d4e6f1;\">William Wallace and G. W. F. Hegel: Prolegomena to the Study of Hegel's Philosophy</span>, <span style=\"background-color:#d6eaf8;\">G. W. Leibniz: Theodicy</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Friedrich Hegel: Hegel's Philosophy of Mind</span>, <span style=\"background-color:#d6dbdf;\">Immanuel Kant: Kant's Critique of Judgement</span>, <span style=\"background-color:#fdebd0;\">Immanuel Kant: The Critique of Practical Reason</span>, <span style=\"background-color:#e2d7d5;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#d4e6e1;\">Immanuel Kant: Kant's Prolegomena</span>, <span style=\"background-color:#eadbd8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#d6dbdf;\">David Hume: Philosophical Works, Vol. 2 of 4</span>, <span style=\"background-color:#ecf3cf;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 3 of 4</span>, <span style=\"background-color:#e5e8e8;\">Friedrich Nietzsche: The Joyful Wisdom</span>, <span style=\"background-color:#d4e6e1;\">Montaigne, Michel, Sainte-Beuve, Charles-Augustin; Renan, Ernest, Lessing, Gotthold Ephraim, Von Schiller, J.C., Kant, Immanuel, Mazzini, and Giuseppe: Literary and Philosophical Essays</span>, <span style=\"background-color:#fdebd0;\">Arthur Schopenhauer: The Basis of Morality</span>, <span style=\"background-color:#f6ddcc;\">David Hume: Philosophical Works, Vol. 1 of 4</span>, <span style=\"background-color:#edebd0;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span>, <span style=\"background-color:#d0ece7;\">Rene Descartes: Discourse of a Method for the Well Guiding of Reason</span></p></small>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Temperature 1.0:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Menstand Befenner, up in h<span style=\"background-color:#d6dbdf;\">e<br>is an en</span><span style=\"background-color:#e5e8e8;\">forced nature</span>. H<span style=\"background-color:#fae5d3;\">e is taken f</span>u<span style=\"background-color:#ecf3cf;\">lly arises, </span><span style=\"background-color:#e2d7d5;\">in the Being </span>amongs<span style=\"background-color:#d4e6e1;\">t wants of</span><span style=\"background-color:#d6eaf8;\">ten reason</span><span style=\"background-color:#d0ece7;\">. For in<br>o</span><span style=\"background-color:#d6eaf8;\">ne, philosophy </span>t<span style=\"background-color:#edebd0;\">ook on every</span><span style=\"background-color:#e2d7d5;\">thing to him </span><span style=\"background-color:#ecf3cf;\">who genera</span>t<span style=\"background-color:#edebd0;\">es a final </span><span style=\"background-color:#e2d7d5;\">direction, in </span><span style=\"background-color:#ecf3cf;\">our attempts </span><span style=\"background-color:#ebdef0;\">of denial,</span><span style=\"background-color:#ebdef0;\"> the egoism </span><span style=\"background-color:#e5e8e8;\">itself. This pr</span>oduce anybodism<span style=\"background-color:#ecf3cf;\"> or Necessity</span><span style=\"background-color:#d8daef;\"> as they ma</span>ster far<span style=\"background-color:#d8daef;\"> encreasing the </span><span style=\"background-color:#d6eaf8;\">creatures, and h</span>avpen brea<span style=\"background-color:#d6dbdf;\">rn of our </span><span style=\"background-color:#fdebd0;\">self-subject</span>; m<span style=\"background-color:#eadbd8;\">en unceasing</span><span style=\"background-color:#d0ece7;\"> the invincible f</span><span style=\"background-color:#ebdef0;\">eelings are in </span><span style=\"background-color:#edebd0;\">the particular em</span><span style=\"background-color:#d6dbdf;\">pirical,<br>the</span><span style=\"background-color:#eadbd8;\"> true history </span><span style=\"background-color:#d6dbdf;\">of religion, is </span><span style=\"background-color:#ecf3cf;\">of natural s</span>la<span style=\"background-color:#d8daef;\">ves.<br><br>The </span><span style=\"background-color:#ecf3cf;\">characteristic im</span><span style=\"background-color:#eadbd8;\">manent place</span><span style=\"background-color:#eadbd8;\">s are one, and</span><span style=\"background-color:#ebdef0;\"> for the spirit, </span><span style=\"background-color:#d8daef;\">for it might </span>ge<span style=\"background-color:#edebd0;\">t before, a</span>ll lif<span style=\"background-color:#d6eaf8;\">e Good to </span>u<span style=\"background-color:#e5e8e8;\">s, breaks forth </span><span style=\"background-color:#d0ece7;\">against such a </span><span style=\"background-color:#d0ece7;\">natural part</span><span style=\"background-color:#fdebd0;\"> is a scientific c</span><span style=\"background-color:#e5e8e8;\">ause and for</span><span style=\"background-color:#ebdef0;\">m which is si</span>mply p<span style=\"background-color:#eadbd8;\">aintained i</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d6dbdf;\">David Hume: Philosophical Works, Vol. 2 of 4</span>, <span style=\"background-color:#e5e8e8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 3 of 3)</span>, <span style=\"background-color:#fae5d3;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#ecf3cf;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 3 of 4</span>, <span style=\"background-color:#e2d7d5;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#d4e6e1;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 2 of 3)</span>, <span style=\"background-color:#d6eaf8;\">G. W. Leibniz: Theodicy</span>, <span style=\"background-color:#d0ece7;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 1 of 4</span>, <span style=\"background-color:#edebd0;\">David Hume: An Enquiry Concerning the Principles of Morals</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Wilhelm Nietzsche: Human, All-Too-Human, Part II</span>, <span style=\"background-color:#edebd0;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 4 of 4</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span>, <span style=\"background-color:#ebdef0;\">Friedrich Wilhelm Nietzsche: Twilight of the Idols - The Antichrist</span>, <span style=\"background-color:#e5e8e8;\">Immanuel Kant: Fundamental Principles of the Metaphysic of Morals</span>, <span style=\"background-color:#ecf3cf;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 1 of 3</span>, <span style=\"background-color:#d8daef;\">Søren Kierkegaard: Selections from the Writings of Kierkegaard</span>, <span style=\"background-color:#d8daef;\">David Hume: A Treatise of Human Nature, Vols. 1 & 2</span>, <span style=\"background-color:#fdebd0;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#eadbd8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#d0ece7;\">Friedrich Nietzsche: Early Greek Philosophy & Other Essays</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Friedrich Hegel: Hegel's Philosophy of Mind</span>, <span style=\"background-color:#d6dbdf;\">Immanuel Kant: Kant's Critique of Judgement</span>, <span style=\"background-color:#eadbd8;\">Rene Descartes: Selections From The Principles of Philosophy</span>, <span style=\"background-color:#edebd0;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 2 of 3</span>, <span style=\"background-color:#d6eaf8;\">G. W. F. Hegel: The Logic of Hegel</span>, <span style=\"background-color:#e5e8e8;\">Friedrich Nietzsche: The Joyful Wisdom</span>, <span style=\"background-color:#fdebd0;\">Arthur Schopenhauer: The Basis of Morality</span>, <span style=\"background-color:#eadbd8;\">David Hume: Hume's Political Discourses</span></p></small>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19500 Loss: 1.2058976480960846 Precision: 0.6280924479166666\n",
            "saved last model data, prec=0.6280924479166666\n",
            "Temperature 0.6:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"background-color:#d6dbdf;\">There is a very </span><span style=\"background-color:#eadbd8;\">both completely </span><span style=\"background-color:#d4e6f1;\">appreciated w</span><span style=\"background-color:#d6dbdf;\">ith the possible<br></span><span style=\"background-color:#e5e8e8;\">perception for </span><span style=\"background-color:#d6dbdf;\">a conformity with </span><span style=\"background-color:#fdebd0;\">the moral law of </span><span style=\"background-color:#d6eaf8;\">previous li</span>fe<span style=\"background-color:#d0ece7;\">, the benefi</span><span style=\"background-color:#d6eaf8;\">t of the bon</span><span style=\"background-color:#fdebd0;\">d of the vari</span><span style=\"background-color:#d8daef;\">ed but one </span>ma<span style=\"background-color:#d4efdf;\">y after ha</span><span style=\"background-color:#d4e6e1;\">ppily discover</span><span style=\"background-color:#d6eaf8;\"> the actual be</span><span style=\"background-color:#e2d7d5;\">ing of this concept</span><span style=\"background-color:#d8daef;\"> which<br>is the object of </span><span style=\"background-color:#d4e6e1;\">common subject, </span><span style=\"background-color:#ecf3cf;\">and the conception of </span><span style=\"background-color:#d4efdf;\">particular reality </span><span style=\"background-color:#fdebd0;\">and backwards, </span><span style=\"background-color:#e5e8e8;\">and in such a m</span><span style=\"background-color:#d4e6e1;\">an we can a</span><span style=\"background-color:#e5e8e8;\">dd, because </span><span style=\"background-color:#e2d7d5;\">the moment of the<br></span><span style=\"background-color:#d4efdf;\">principle of the desir</span><span style=\"background-color:#f6ddcc;\">es and against </span><span style=\"background-color:#e2d7d5;\">one another, however</span><span style=\"background-color:#eadbd8;\"> determined the </span><span style=\"background-color:#d0ece7;\">mere action</span><span style=\"background-color:#d8daef;\"> of God is a </span><span style=\"background-color:#d4efdf;\">soul, and that </span><span style=\"background-color:#d4e6f1;\">a machine </span><span style=\"background-color:#d6dbdf;\">should be conceived </span><span style=\"background-color:#f6ddcc;\">to overcome a</span><span style=\"background-color:#ecf3cf;\"> content, we </span>now<span style=\"background-color:#eadbd8;\"> seek to e</span><span style=\"background-color:#eadbd8;\">ndure the </span><span style=\"background-color:#d6eaf8;\">changes of<br>p</span><span style=\"background-color:#ecf3cf;\">ractical form</span><span style=\"background-color:#d4efdf;\">er, that a </span><span style=\"background-color:#d0ece7;\">pressure of al</span>t<span style=\"background-color:#fae5d3;\">ering is a </span><span style=\"background-color:#d8daef;\">character. That </span><span style=\"background-color:#edebd0;\">which is able to </span><span style=\"background-color:#ecf3cf;\">confound the con</span><span style=\"background-color:#e2d7d5;\">trary being </span>th"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d6dbdf;\">David Hume: Philosophical Works, Vol. 2 of 4</span>, <span style=\"background-color:#eadbd8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#d4e6f1;\">William Wallace and G. W. F. Hegel: Prolegomena to the Study of Hegel's Philosophy</span>, <span style=\"background-color:#d6dbdf;\">Immanuel Kant: Kant's Critique of Judgement</span>, <span style=\"background-color:#e5e8e8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 3 of 3)</span>, <span style=\"background-color:#fdebd0;\">Immanuel Kant: The Critique of Practical Reason</span>, <span style=\"background-color:#d6eaf8;\">G. W. Leibniz: Theodicy</span>, <span style=\"background-color:#d0ece7;\">Friedrich Nietzsche: Early Greek Philosophy & Other Essays</span>, <span style=\"background-color:#d6eaf8;\">Arthur Schopenhauer: On the Fourfold Root of the Principle of Sufficient Reason and On the Will in Nature: Two Essays (revised edition)</span>, <span style=\"background-color:#fdebd0;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#d8daef;\">Søren Kierkegaard: Selections from the Writings of Kierkegaard</span>, <span style=\"background-color:#d4efdf;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 2 of 4</span>, <span style=\"background-color:#d4e6e1;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 2 of 3)</span>, <span style=\"background-color:#e2d7d5;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#d8daef;\">David Hume: A Treatise of Human Nature, Vols. 1 & 2</span>, <span style=\"background-color:#d4e6e1;\">Montaigne, Michel, Sainte-Beuve, Charles-Augustin; Renan, Ernest, Lessing, Gotthold Ephraim, Von Schiller, J.C., Kant, Immanuel, Mazzini, and Giuseppe: Literary and Philosophical Essays</span>, <span style=\"background-color:#ecf3cf;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 3 of 4</span>, <span style=\"background-color:#fdebd0;\">Arthur Schopenhauer: The Basis of Morality</span>, <span style=\"background-color:#d4efdf;\">Friedrich Nietzsche: Thus Spake Zarathustra</span>, <span style=\"background-color:#f6ddcc;\">Georg Hegel: The Introduction to Hegel's Philosophy of Fine Arts</span>, <span style=\"background-color:#eadbd8;\">David Hume: Hume's Political Discourses</span>, <span style=\"background-color:#d0ece7;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 1 of 4</span>, <span style=\"background-color:#f6ddcc;\">David Hume: Philosophical Works, Vol. 1 of 4</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span>, <span style=\"background-color:#fae5d3;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#d8daef;\">Friedrich Wilhelm Nietzsche: The Dawn of Day</span>, <span style=\"background-color:#edebd0;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 4 of 4</span></p></small>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Temperature 0.8:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"background-color:#d6dbdf;\">Now, this is the </span>former s<span style=\"background-color:#d6dbdf;\">ound subject</span><span style=\"background-color:#d8daef;\">ed<br>that for </span>all _jusgments<span style=\"background-color:#edebd0;\">_ remains </span><span style=\"background-color:#d8daef;\">unless it i</span><span style=\"background-color:#d4efdf;\">n its real and </span><span style=\"background-color:#eadbd8;\">facility, </span>for I amay<span style=\"background-color:#e2d7d5;\"><br>see the s</span>am<span style=\"background-color:#e2d7d5;\">e law and </span><span style=\"background-color:#edebd0;\">variable caus</span><span style=\"background-color:#d4efdf;\">es of Nature, as </span><span style=\"background-color:#d4efdf;\">well as fac</span><span style=\"background-color:#ecf3cf;\">ulty of which in</span><span style=\"background-color:#eadbd8;\">stead of tho</span><span style=\"background-color:#d6dbdf;\">ught and conception</span><span style=\"background-color:#ecf3cf;\">s.<br><br>The conception of </span><span style=\"background-color:#d4efdf;\">the time was </span><span style=\"background-color:#e2d7d5;\">the century of th</span><span style=\"background-color:#d6eaf8;\">at reason in c</span><span style=\"background-color:#edebd0;\">ertain writ</span><span style=\"background-color:#d6eaf8;\">ings of the very </span><span style=\"background-color:#d4efdf;\">order and the o</span><span style=\"background-color:#ecf3cf;\">ne.<br><br><br><br><br>11</span><span style=\"background-color:#ebdef0;\"><br><br><br>                                                                    </span><span style=\"background-color:#ebdef0;\">                                                     </span><span style=\"background-color:#eadbd8;\">The Editor</span>s<span style=\"background-color:#d6eaf8;\">. 2_s._ 6_d._</span><br>    A<span style=\"background-color:#d0ece7;\"> hand for </span><span style=\"background-color:#eadbd8;\">myself, to </span><span style=\"background-color:#d4e6f1;\">a concept of the </span><span style=\"background-color:#e2d7d5;\">transference of the </span><span style=\"background-color:#d0ece7;\">Absolute. It is </span><span style=\"background-color:#d6eaf8;\">always the co</span><span style=\"background-color:#d6dbdf;\">ld way of </span><span style=\"background-color:#ebdef0;\">him, who fo</span><span style=\"background-color:#e2d7d5;\">llowed and </span>pre<span style=\"background-color:#ebdef0;\">sume as th</span><span style=\"background-color:#ecf3cf;\">is as a pr</span>op<span style=\"background-color:#ecf3cf;\">er separation.</span> One al<span style=\"background-color:#d0ece7;\">equate to the conception of </span>Eumen"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#d6dbdf;\">David Hume: Philosophical Works, Vol. 2 of 4</span>, <span style=\"background-color:#d8daef;\">Friedrich Wilhelm Nietzsche: The Genealogy of Morals</span>, <span style=\"background-color:#edebd0;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 4 of 4</span>, <span style=\"background-color:#d8daef;\">Søren Kierkegaard: Selections from the Writings of Kierkegaard</span>, <span style=\"background-color:#d4efdf;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 2 of 4</span>, <span style=\"background-color:#eadbd8;\">David Hume: Hume's Political Discourses</span>, <span style=\"background-color:#e2d7d5;\">Friedrich Nietzsche: Thoughts Out of Season, Part 2</span>, <span style=\"background-color:#e2d7d5;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: Human, All Too Human</span>, <span style=\"background-color:#d4efdf;\">David Hume: Essays</span>, <span style=\"background-color:#ecf3cf;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 3 of 4</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span>, <span style=\"background-color:#d4efdf;\">Friedrich Wilhelm Nietzsche: On the Future of our Educational Institutions - Homer and Classical Philology</span>, <span style=\"background-color:#e2d7d5;\">Friedrich Nietzsche: Beyond Good and Evil</span>, <span style=\"background-color:#d6eaf8;\">G. W. Leibniz: Theodicy</span>, <span style=\"background-color:#d6eaf8;\">G. W. F. Hegel: The Logic of Hegel</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Wilhelm Nietzsche: Human, All-Too-Human, Part II</span>, <span style=\"background-color:#ebdef0;\">Hubert Crackanthorpe: Vignettes</span>, <span style=\"background-color:#d6eaf8;\">Arthur Schopenhauer: On the Fourfold Root of the Principle of Sufficient Reason and On the Will in Nature: Two Essays (revised edition)</span>, <span style=\"background-color:#d0ece7;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 1 of 4</span>, <span style=\"background-color:#eadbd8;\">Friedrich Wilhelm Nietzsche: Ecce Homo</span>, <span style=\"background-color:#d4e6f1;\">William Wallace and G. W. F. Hegel: Prolegomena to the Study of Hegel's Philosophy</span>, <span style=\"background-color:#d6dbdf;\">Immanuel Kant: Kant's Critique of Judgement</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Friedrich Hegel: Hegel's Philosophy of Mind</span>, <span style=\"background-color:#ebdef0;\">Friedrich Wilhelm Nietzsche: Twilight of the Idols - The Antichrist</span>, <span style=\"background-color:#ecf3cf;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 1 of 3</span></p></small>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Temperature 1.0:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Wokk<span style=\"background-color:#e2d7d5;\"> he learned</span><span style=\"background-color:#e2d7d5;\">, the determinate </span><span style=\"background-color:#edebd0;\">type, which</span><span style=\"background-color:#d4efdf;\"><br>is forced </span><span style=\"background-color:#ecf3cf;\">on the inco</span>nstant modformuch'<span style=\"background-color:#d8daef;\">r, who in a</span><span style=\"background-color:#d6dbdf;\">rt of conduct</span><span style=\"background-color:#e2d7d5;\"> with the will, </span>n<span style=\"background-color:#eadbd8;\">or do not </span><span style=\"background-color:#eadbd8;\">form every </span><span style=\"background-color:#e5e8e8;\">ages. To the</span><span style=\"background-color:#e5e8e8;\"> effect of human</span>ity—<span style=\"background-color:#d4efdf;\">is not indu</span>ced,<span style=\"background-color:#d6eaf8;\"> \"that God</span>'<span style=\"background-color:#fdebd0;\">s time has </span>a m<span style=\"background-color:#d4efdf;\">an where h</span>i<span style=\"background-color:#eadbd8;\">s cases, a</span><span style=\"background-color:#e2d7d5;\">s for the mo</span>od<span style=\"background-color:#fae5d3;\"> not crushed </span><span style=\"background-color:#ecf3cf;\">himself a we</span>ll-b<span style=\"background-color:#ecf3cf;\">ot the rule</span><span style=\"background-color:#ecf3cf;\"> of this definite </span>note.<br>By<span style=\"background-color:#eadbd8;\"> our<br>eyes </span><span style=\"background-color:#eadbd8;\">from the Gree</span>d<span style=\"background-color:#d8daef;\">s. He lost</span><span style=\"background-color:#d6eaf8;\">ed with their m</span>ajb<span style=\"background-color:#fae5d3;\">es<br>his power </span>for th<span style=\"background-color:#ecf3cf;\">y only from </span><span style=\"background-color:#d4efdf;\">which it me</span><span style=\"background-color:#d4e6f1;\">ans that the ca</span>use of Jawfal,<span style=\"background-color:#edebd0;\"> who again and </span>help ha<span style=\"background-color:#d6eaf8;\">d freely, </span><span style=\"background-color:#ebdef0;\">poetry,<br>and the </span>elev<span style=\"background-color:#edebd0;\">ates simply</span><span style=\"background-color:#edebd0;\">, unable to </span><span style=\"background-color:#d6eaf8;\">find all the e</span>nd--cold<span style=\"background-color:#ecf3cf;\"> of solution and </span><span style=\"background-color:#d8daef;\">who has treated </span><span style=\"background-color:#d8daef;\">a representation of </span><span style=\"background-color:#fdebd0;\">her harmful</span><span style=\"background-color:#e2d7d5;\"> movement.<br></span>By Hreakin<span style=\"background-color:#ecf3cf;\">gs, a little </span>revere<span style=\"background-color:#d6eaf8;\">ncy to your</span><span style=\"background-color:#d4efdf;\"> events with the</span><span style=\"background-color:#eadbd8;\">ir possessions </span><span style=\"background-color:#d4efdf;\">for examples</span>, t"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<small><p style=\"text-align:right;\">Sources: <span style=\"background-color:#e2d7d5;\">Georg Wilhelm Hegel: The History of Philosophy: Volume 3 of 3</span>, <span style=\"background-color:#edebd0;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 4 of 4</span>, <span style=\"background-color:#d4efdf;\">G. W. F. Hegel: The Philosophy of Fine Art, Vol. 2 of 4</span>, <span style=\"background-color:#ecf3cf;\">G. W. F. Hegel: The Philosophy of Fine Art, Volume 3 of 4</span>, <span style=\"background-color:#d8daef;\">Søren Kierkegaard: Selections from the Writings of Kierkegaard</span>, <span style=\"background-color:#d6dbdf;\">Immanuel Kant: Kant's Critique of Judgement</span>, <span style=\"background-color:#eadbd8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 1 of 3)</span>, <span style=\"background-color:#eadbd8;\">Friedrich Wilhelm Nietzsche: Ecce Homo</span>, <span style=\"background-color:#e5e8e8;\">Arthur Schopenhauer: The World as Will and Idea (Vol. 3 of 3)</span>, <span style=\"background-color:#d4efdf;\">David Hume: Essays</span>, <span style=\"background-color:#d6eaf8;\">G. W. Leibniz: Theodicy</span>, <span style=\"background-color:#fdebd0;\">Arthur Schopenhauer: The Basis of Morality</span>, <span style=\"background-color:#fae5d3;\">Friedrich Nietzsche: The Will to Power, Books III and IV</span>, <span style=\"background-color:#ecf3cf;\">Friedrich Wilhelm Nietzsche: Human, All-Too-Human, Part II</span>, <span style=\"background-color:#ecf3cf;\">Georg Wilhelm Hegel: Hegel's Lectures on the History of Philosophy: Vol. 1 of 3</span>, <span style=\"background-color:#eadbd8;\">David Hume: Hume's Political Discourses</span>, <span style=\"background-color:#d6eaf8;\">G. W. F. Hegel: The Logic of Hegel</span>, <span style=\"background-color:#ecf3cf;\">Immanuel Kant: The Critique of Pure Reason</span>, <span style=\"background-color:#d4e6f1;\">William Wallace and G. W. F. Hegel: Prolegomena to the Study of Hegel's Philosophy</span>, <span style=\"background-color:#edebd0;\">Friedrich Nietzsche: Human, All Too Human</span>, <span style=\"background-color:#ebdef0;\">Georg Wilhelm Friedrich Hegel: Hegel's Philosophy of Mind</span>, <span style=\"background-color:#d6eaf8;\">Arthur Schopenhauer: On the Fourfold Root of the Principle of Sufficient Reason and On the Will in Nature: Two Essays (revised edition)</span>, <span style=\"background-color:#d8daef;\">Friedrich Wilhelm Nietzsche: The Genealogy of Morals</span>, <span style=\"background-color:#fdebd0;\">Friedrich Nietzsche: The Will to Power, Books I and II</span>, <span style=\"background-color:#d4efdf;\">Friedrich Wilhelm Nietzsche: On the Future of our Educational Institutions - Homer and Classical Philology</span></p></small>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-a25462b468b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2500000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mintv\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-3d136db65035>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Xt = Tensor(torch.from_numpy(np.array(Xo,dtype=np.float32)), requires_grad=False, dtype=torch.float32, device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# yt = Tensor(torch.from_numpy(y), requires_grad=False, dtype=torch.int32, device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mXt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-dsSPjPsUlpY"
      },
      "source": [
        "# 4. Text generation\n",
        "\n",
        "## 4.1 Sample generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u-vHDcHupruq",
        "colab": {}
      },
      "source": [
        "load_checkpoint(filename=\"model_best.pth.tar\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oflaWxltsJd6",
        "colab": {}
      },
      "source": [
        "print(\"Sample text:\")\n",
        "print(\"\")\n",
        "for temperature in [0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6]:\n",
        "    tgen=poet.generate(1000,\"\\n\\n\", temperature=temperature)\n",
        "    print(f\"================Temperature: {temperature}==============\")\n",
        "    detectPlagiarism(tgen, textlib, display_ref_anchor=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wdpCtjvfUlpZ",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "def detectPlagiarism(generatedtext, textlibrary, minQuoteLength=10, display_ref_anchor=True):\n",
        "    textlibrary.source_highlight(generatedtext, minQuoteSize=minQuoteLength,dark_mode=use_dark_mode, display_ref_anchor=display_ref_anchor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hjCd8CHLUlpd"
      },
      "source": [
        "## 4.2 Dialog with the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pfiL1_64Ulpe",
        "colab": {}
      },
      "source": [
        "# Do a dialog with the recursive neural net trained above:\n",
        "def doDialog():\n",
        "    temperature = 0.8  # 0.1 (free-style chaos) - >1.0 (rigid, frozen)\n",
        "    endPrompt = '.'  # the endPrompt character is the end-mark in answers.\n",
        "    # maxEndPrompts = 4  # look for number of maxEndPrompts until answer is finished.\n",
        "    # maxAnswerSize = 2048  # Maximum length of the answer\n",
        "    # minAnswerSize = 64  # Minimum length of the answer\n",
        "\n",
        "    \n",
        "    print(\"Please enter some dialog.\")\n",
        "    print(\"The net will answer according to your input.\")\n",
        "    print(\"'bye' for end,\")\n",
        "    print(\"'reset' to reset the conversation context,\")\n",
        "    print(\"'temperature=<float>' [0.1(free, chaotic) - >1.0(strict, frozen)]\")\n",
        "    print(\"    to change character of the dialog.\")\n",
        "    # print(\"    Current temperature={}.\".format(temperature))\n",
        "    print()\n",
        "    xso = None\n",
        "    bye = False\n",
        "    last_ans=\"\"\n",
        "        \n",
        "    while not bye:\n",
        "        print(\"> \", end=\"\")\n",
        "        prompt = input()\n",
        "        if prompt == 'bye':\n",
        "            bye = True\n",
        "            print(\"Good bye!\")\n",
        "            continue\n",
        "        if prompt.find(\"temperature\")>=0 and prompt.find(\"=\") > prompt.find(\"temperature\"):\n",
        "            temperature=float(prompt[prompt.find('=')+1:])\n",
        "            print(f\"Temperature set to {temperature}\")\n",
        "            continue\n",
        "        for attempts in range(1,3):\n",
        "            tgen=poet.generate(1000,last_ans+\"\\n\\n\"+prompt,temperature=temperature)\n",
        "            i=tgen.find(endPrompt)\n",
        "            tgen=tgen.replace(\"Mr.\", \"Mr\")\n",
        "            tgen=tgen.replace(\"Mrs.\", \"Mrs\")\n",
        "            tgen=tgen.replace(\"\\n\",\" \")\n",
        "            tgen=tgen.replace(\"  \",\" \")\n",
        "            i2=tgen[i+1:].find(endPrompt)+i\n",
        "            i3=tgen[i2+1:].find(endPrompt)+i2\n",
        "            tgen=tgen[i+1:i3+2]\n",
        "            if len(tgen)>10:\n",
        "                break\n",
        "        last_ans=tgen\n",
        "        textlib.source_highlight(tgen, minQuoteSize=10,dark_mode=use_dark_mode,display_ref_anchor=False)\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8mGGsuFRUlpi",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "doDialog()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eON9sYdz_1lh",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}